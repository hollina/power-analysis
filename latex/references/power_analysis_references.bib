@article{kaestnerMortalityScienceComment2021,
  title = {Mortality and {{Science}}: A {{Comment}} on {{Two Articles}} on the {{Effects}} of {{Health Insurance}} on {{Mortality}}},
  author = {Kaestner, Robert},
  year = {2021},
  journal = {Econ Journal Watch},
  volume = {18},
  number = {2},
  pages = {192--211},
  langid = {english},
  file = {/Users/hollinal/Zotero/storage/YRXGRAZE/Kaestner - 2021 - Mortality and Science A Comment on Two Articles o.pdf}
}



@article{huhMedicareMortality2017,
title = {Did Medicare Part D reduce mortality?},
journal = {Journal of Health Economics},
volume = {53},
pages = {17-37},
year = {2017},
issn = {0167-6296},
doi = {https://doi.org/10.1016/j.jhealeco.2017.01.005},
url = {https://www.sciencedirect.com/science/article/pii/S0167629617300577},
author = {Jason Huh and Julian Reif},
abstract = {We investigate the implementation of Medicare Part D and estimate that this prescription drug benefit program reduced elderly mortality by 2.2\% annually. This was driven primarily by a reduction in cardiovascular mortality, the leading cause of death for the elderly. There was no effect on deaths due to cancer, a condition whose drug treatments are covered under Medicare Part B. We validate these results by demonstrating that the changes in drug utilization following the implementation of Medicare Part D match the mortality patterns we observe. We calculate that the value of the mortality reduction is equal to $5 billion per year.}
}

@article{lindoAggregationEstimatedEffects2015,
  title = {Aggregation and the Estimated Effects of Economic Conditions on Health},
  author = {Lindo, Jason M.},
  year = {2015},
  month = mar,
  volume = {40},
  pages = {83--96},
  issn = {01676296},
  doi = {10.1016/j.jhealeco.2014.11.009},
  abstract = {This paper considers the relationship between economic conditions and health with a focus on different approaches to geographic aggregation. After reviewing the tradeoffs associated with more- and less-disaggregated analyses, I update earlier state-level analyses of mortality and infant health and then consider how the estimated effects vary when the analysis is conducted at differing levels of geographic aggregation. This analysis reveals that the results are sensitive to the level of geographic aggregation with more-disaggregated analyses\textemdash particularly county-level analyses\textemdash routinely producing estimates that are smaller in magnitude. Further analyses suggest this is due to spillover effects of economic conditions on health outcomes across counties.},
  file = {files/2949/Lindo - 2015 - Aggregation and the estimated effects of economic .pdf},
  journal = {Journal of Health Economics},
  language = {en}
}



@article{johnsonWhenLessMore2017a,
  title = {When {{Less Is More}}: {{Data}} and {{Power}} in {{Advertising Experiments}}},
  shorttitle = {When {{Less Is More}}},
  author = {Johnson, Garrett A. and Lewis, Randall A. and Reiley, David H.},
  year = {2017},
  month = jan,
  volume = {36},
  pages = {43--53},
  issn = {0732-2399, 1526-548X},
  doi = {10.1287/mksc.2016.0998},
  abstract = {Yahoo! Research partnered with a nationwide retailer to study the effects of online display advertising on both online and in-store purchases. We use a randomized field experiment on 3 million Yahoo! users who are also past customers of the retailer. We find statistically significant evidence that the retailer ads increase sales 3.6\% relative to the control group. We show that control ads boost measurement precision by identifying and removing the half of in-campaign sales data that are unaffected by the ads. Less data give us 31\% more precision in our estimates\textemdash equivalent to increasing our sample to 5.3 million users. By contrast, we only improve precision by 5\% when we include additional covariate data to reduce the residual variance in our experimental regression. The covariate-adjustment strategy disappoints despite exceptional consumer-level data including demographics, ad exposure levels, and two years' worth of past purchase history.},
  file = {files/3537/Johnson et al. - 2017 - When Less Is More Data and Power in Advertising E.pdf},
  journal = {Marketing Science},
  language = {en},
  number = {1}
}

@article{lewisOnlineAdsOffline2014,
  title = {Online Ads and Offline Sales: Measuring the Effect of Retail Advertising via a Controlled Experiment on {{Yahoo}}!},
  shorttitle = {Online Ads and Offline Sales},
  author = {Lewis, Randall A. and Reiley, David H.},
  year = {2014},
  month = sep,
  volume = {12},
  pages = {235--266},
  issn = {1570-7156, 1573-711X},
  doi = {10.1007/s11129-014-9146-6},
  abstract = {A randomized experiment with 1.6 million customers measures positive causal effects of online advertising for a major retailer. The advertising profitably increases purchases by 5 \%. 93 \% of the increase occurs in brick-and-mortar stores; 78 \% of the increase derives from consumers who never click the ads. Our large sample reaches the statistical frontier for measuring economically relevant effects. We improve econometric efficiency by supplementing our experimental variation with non-experimental variation caused by consumer browsing behavior. Our experiment provides a specification check for observational difference-in-differences and crosssectional estimators; the latter exhibits a large negative bias three times the estimated experimental effect.},
  file = {files/3535/Lewis and Reiley - 2014 - Online ads and offline sales measuring the effect.pdf},
  journal = {Quantitative Marketing and Economics},
  language = {en},
  number = {3}
}



@article{Courtemanche2017MedicaidandInsurance,
author = {Courtemanche, Charles and Marton, James and Ukert, Benjamin and Yelowitz, Aaron and Zapata, Daniela},
title = {Early Impacts of the Affordable Care Act on Health Insurance Coverage in Medicaid Expansion and Non-Expansion States},
journal = {Journal of Policy Analysis and Management},
volume = {36},
number = {1},
pages = {178-210},
doi = {https://doi.org/10.1002/pam.21961},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/pam.21961},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/pam.21961},
abstract = {Abstract The Affordable Care Act (ACA) aimed to achieve nearly universal health insurance coverage in the United States through a combination of insurance market reforms, mandates, subsidies, health insurance exchanges, and Medicaid expansions, most of which took effect in 2014. This paper estimates the causal effects of the ACA on health insurance coverage in 2014 using data from the American Community Survey. We utilize difference-in-difference-in-differences models that exploit cross-sectional variation in the intensity of treatment arising from state participation in the Medicaid expansion and local area pre-ACA uninsured rates. This strategy allows us to identify the effects of the ACA in both Medicaid expansion and non-expansion states. Our preferred specification suggests that, at the average pre-treatment uninsured rate, the full ACA increased the proportion of residents with insurance by 5.9 percentage points compared to 2.8 percentage points in states that did not expand Medicaid. Private insurance expansions from the ACA were due to increases in both employer-provided and non-group coverage. The coverage gains from the full ACA were largest for those without a college degree, non-whites, young adults, unmarried individuals, and those without children in the home. We find no evidence that the Medicaid expansion crowded out private coverage.},
year = {2017}
}


@article{Wehby2018MedicaidandInsuranceProb,
author = {Wehby, George L. and Lyu, Wei},
title = {The Impact of the ACA Medicaid Expansions on Health Insurance Coverage through 2015 and Coverage Disparities by Age, Race/Ethnicity, and Gender},
journal = {Health Services Research},
volume = {53},
number = {2},
pages = {1248-1271},
keywords = {Medicaid, insurance, disparities},
doi = {https://doi.org/10.1111/1475-6773.12711},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/1475-6773.12711},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/1475-6773.12711},
abstract = {Objective Examine the ACA Medicaid expansion effects on Medicaid take-up and private coverage through 2015 and coverage disparities by age, race/ethnicity, and gender. Data Sources 2011–2015 American Community Survey for 3,137,989 low-educated adults aged 19–64 years. Study Design Difference-in-differences regressions accounting for national coverage trends and state fixed effects. Principal Findings Expansion effects doubled in 2015 among low-educated adults, with a nearly 8 percentage-point increase in Medicaid take-up and 6 percentage-point decline in uninsured rate. Significant coverage gains were observed across virtually all examined groups by age, gender, and race/ethnicity. Take-up and insurance declines were strongest among younger adults and were generally close by gender and race/ethnicity. Despite the increased take-up however, coverage disparities remained sizeable, especially for young adults and Hispanics who had declining but still high uninsured rates in 2015. There was some evidence of private coverage crowd-out in certain subgroups, particularly among young adults aged 19–26 years and women, including in both individually purchased and employer-sponsored coverage. Conclusions The ACA Medicaid expansions have continued to increase coverage in 2015 across the entire population of low-educated adults and have reduced age disparities in coverage. However, there is still a need for interventions that target eligible young and Hispanic adults.},
year = {2018}
}

@article{Davern2009MedicaidUndercountInSurveys,
author = {Davern, Michael and Klerman, Jacob Alex and Baugh, David K. and Call, Kathleen Thiede and Greenberg, George D.},
title = {An Examination of the Medicaid Undercount in the Current Population Survey: Preliminary Results from Record Linking},
journal = {Health Services Research},
volume = {44},
number = {3},
pages = {965-987},
keywords = {Medicaid undercount, MSIS, CPS-ASEC, survey measurement error, Medicaid},
doi = {https://doi.org/10.1111/j.1475-6773.2008.00941.x},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1475-6773.2008.00941.x},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1475-6773.2008.00941.x},
abstract = {Objective. To assess reasons why survey estimates of Medicaid enrollment are 43 percent lower than raw Medicaid program enrollment counts (i.e., “Medicaid undercount”). Data Sources. Linked 2000–2002 Medicaid Statistical Information System (MSIS) and the 2001–2002 Current Population Survey (CPS). Data Collection Methods. Centers for Medicare and Medicaid Services provided the Census Bureau with its MSIS file. The Census Bureau linked the MSIS to the CPS data within its secure data analysis facilities. Study Design. We analyzed how often Medicaid enrollees incorrectly answer the CPS health insurance item and imperfect concept alignment (e.g., inclusion in the MSIS of people who are not included in the CPS sample frame and people who were enrolled in Medicaid in more than one state during the year). Principal Findings. The extent to which the Medicaid enrollee data were adjusted for imperfect concept alignment reduces the raw Medicaid undercount considerably (by 12 percentage points). However, survey response errors play an even larger role with 43 percent of Medicaid enrollees answering the CPS as though they were not enrolled and 17 percent reported being uninsured. Conclusions. The CPS is widely used for health policy analysis but is a poor measure of Medicaid enrollment at any time during the year because many people who are enrolled in Medicaid fail to report it and may be incorrectly coded as being uninsured. This discrepancy should be considered when using the CPS for policy research.},
year = {2009}
}

@article{Kaestner2016,
author = {Robert Kaestner},
title = {Did Massachusetts Health Care Reform Lower Mortality? No According to Randomization Inference},
journal = {Statistics and Public Policy},
volume = {3},
number = {1},
pages = {1-6},
year  = {2016},
publisher = {Taylor & Francis},
doi = {10.1080/2330443X.2015.1102667},

URL = { 
        https://doi.org/10.1080/2330443X.2015.1102667
    
},
eprint = { 
        https://doi.org/10.1080/2330443X.2015.1102667
    
}

}




@article{KOLSTAD2012909,
title = "The impact of health care reform on hospital and preventive care: Evidence from Massachusetts",
journal = "Journal of Public Economics",
volume = "96",
number = "11",
pages = "909 - 929",
year = "2012",
note = "Fiscal Federalism",
issn = "0047-2727",
doi = "https://doi.org/10.1016/j.jpubeco.2012.07.003",
url = "http://www.sciencedirect.com/science/article/pii/S0047272712000849",
author = "Jonathan T. Kolstad and Amanda E. Kowalski",
keywords = "Health, Health care, Health reform, Insurance, Hospitals, Massachusetts, Preventive care",
abstract = "In April 2006, Massachusetts passed legislation aimed at achieving near-universal health insurance coverage. The key features of this legislation were a model for national health reform, passed in March 2010. The reform gives us a novel opportunity to examine the impact of expansion to near-universal coverage state-wide. Among hospital discharges in Massachusetts, we find that the reform decreased uninsurance by 36% relative to its initial level and to other states. Reform affected utilization by decreasing length of stay, and the number of inpatient admissions originating from the emergency room. When we control for patient severity, we find evidence that preventable admissions decreased. At the same time, hospital cost growth did not increase."
}



@article{chettyAssociationIncomeLife2016,
  title = {The {{Association Between Income}} and {{Life Expectancy}} in the {{United States}}, 2001-2014},
  author = {Chetty, Raj and Stepner, Michael and Abraham, Sarah and Lin, Shelby and Scuderi, Benjamin and Turner, Nicholas and Bergeron, Augustin and Cutler, David},
  year = {2016},
  month = apr,
  volume = {315},
  pages = {1750},
  issn = {0098-7484},
  doi = {10.1001/jama.2016.4226},
  abstract = {OBJECTIVES To measure the level, time trend, and geographic variability in the association between income and life expectancy and to identify factors related to small area variation. DESIGN AND SETTING Income data for the US population were obtained from 1.4 billion deidentified tax records between 1999 and 2014. Mortality data were obtained from Social Security Administration death records. These data were used to estimate race- and ethnicity-adjusted life expectancy at 40 years of age by household income percentile, sex, and geographic area, and to evaluate factors associated with differences in life expectancy. EXPOSURE Pretax household earnings as a measure of income. MAIN OUTCOMES AND MEASURES Relationship between income and life expectancy; trends in life expectancy by income group; geographic variation in life expectancy levels and trends by income group; and factors associated with differences in life expectancy across areas. RESULTS The sample consisted of 1 408 287 218 person-year observations for individuals aged 40 to 76 years (mean age, 53.0 years; median household earnings among working individuals, \$61 175 per year). There were 4 114 380 deaths among men (mortality rate, 596.3 per 100 000) and 2 694 808 deaths among women (mortality rate, 375.1 per 100 000). The analysis yielded 4 results. First, higher income was associated with greater longevity throughout the income distribution. The gap in life expectancy between the richest 1\% and poorest 1\% of individuals was 14.6 years (95\% CI, 14.4 to 14.8 years) for men and 10.1 years (95\% CI, 9.9 to 10.3 years) for women. Second, inequality in life expectancy increased over time. Between 2001 and 2014, life expectancy increased by 2.34 years for men and 2.91 years for women in the top 5\% of the income distribution, but by only 0.32 yearsformenand0.04yearsforwomeninthebottom5\%(P {$<$} .001forthedifferencesforbothsexes). Third, life expectancy for low-income individuals varied substantially across local areas. In the bottom income quartile, life expectancy differed by approximately 4.5 years between areas with the highest and lowest longevity. Changes in life expectancy between 2001 and 2014 ranged from gains of more than 4 years to losses of more than 2 years across areas. Fourth, geographic differences in life expectancy for individuals in the lowest income quartile were significantly correlated with health behaviors such as smoking (r = -0.69, P {$<$} .001), but were not significantly correlated with access to medical care, physical environmental factors, income inequality, or labor market conditions. Life expectancy for low-income individuals was positively correlated with the local area fraction of immigrants (r = 0.72, P {$<$} .001), fraction of college graduates (r = 0.42, P {$<$} .001), and government expenditures (r = 0.57, P {$<$} .001). CONCLUSIONS AND RELEVANCE In the United States between 2001 and 2014, higher income was associated with greater longevity, and differences in life expectancy across income groups increased over time. However, the association between life expectancy and income varied substantially across areas; differences in longevity across income groups decreased in some areas and increased in others. The differences in life expectancy were correlated with health behaviors and local area characteristics.},
  file = {files/3516/Chetty et al. - 2016 - The Association Between Income and Life Expectancy.pdf},
  journal = {JAMA},
  language = {en},
  number = {16}
}


@article{martonHealthInsuranceGenerosity2015,
  title = {Health Insurance Generosity and Conditional Coverage: {{Evidence}} from Medicaid Managed Care in {{Kentucky}}: {{Medicaid Conditional Coverage}}},
  shorttitle = {Health Insurance Generosity and Conditional Coverage},
  author = {Marton, James and Yelowitz, Aaron},
  year = {2015},
  month = oct,
  volume = {82},
  pages = {535--555},
  issn = {00384038},
  doi = {10.1002/soej.12064},
  file = {/Users/hollinal/Zotero/storage/KZUBZL2L/Marton and Yelowitz - 2015 - Health insurance generosity and conditional covera.pdf},
  journal = {Southern Economic Journal},
  language = {en},
  number = {2}
}


@article {Nolte1129,
  author = {Nolte, Ellen and McKee, Martin},
  title = {Measuring the health of nations: analysis of mortality amenable to health care},
  volume = {327},
  number = {7424},
  pages = {1129},
  year = {2003},
  doi = {10.1136/bmj.327.7424.1129},
  publisher = {BMJ Publishing Group Ltd},
  abstract = {Objective To assess whether and how the rankings of the world{\textquoteright}s health systems based on disability adjusted life expectancy as done in the 2000 World Health Report change when using the narrower concept of mortality amenable to health care, an outcome more closely linked to health system performance. Design Analysis of mortality amenable to health care (including and excluding ischaemic heart disease). Main outcome measure Age standardised mortality from causes amenable to health care Setting 19 countries belonging to the Organisation for Economic Cooperation and Development. Results Rankings based on mortality amenable to health care (excluding ischaemic heart disease) differed substantially from rankings of health attainment given in the 2000 World Health Report. No country retained the same position. Rankings for southern European countries and Japan, which had performed well in the report, fell sharply, whereas those of the Nordic countries improved. Some middle ranking countries (United Kingdom, Netherlands) also fell considerably; New Zealand improved its position. Rankings changed when ischaemic heart disease was included as amenable to health care. Conclusion The 2000 World Health Report has been cited widely to support claims for the merits of otherwise different health systems. High levels of health attainment in well performing countries may be a consequence of good fortune in geography, and thus dietary habits, and success in the health effects of policies in other sectors. When assessed in terms of achievements that are more explicitly linked to health care, their performance may not be as good.},
  issn = {0959-8138},
  URL = {https://www.bmj.com/content/327/7424/1129},
  eprint = {https://www.bmj.com/content/327/7424/1129.full.pdf},
  journal = {BMJ}
}
@techreport{gatesWisconsinBadgerCareProgram2014,
  title = {Wisconsin's {{BadgerCare Program}} and the {{ACA}}},
  author = {Gates, Alexandra and Rudowitz, Robin},
  institution = {{Kaiser Family Foundation}}, 
  year = {2014}
}

@article{sommersACAgainsInYoungAdult2013,
author = {Sommers, Benjamin D. and Buchmueller, Thomas and Decker, Sandra L. and Carey, Colleen and Kronick, Richard},
title = {The Affordable Care Act Has Led To Significant Gains In Health Insurance And Access To Care For Young Adults},
journal = {Health Affairs},
volume = {32},
number = {1},
pages = {165-174},
year = {2013},
doi = {10.1377/hlthaff.2012.0552},
    note ={PMID: 23255048},

URL = { 
        https://doi.org/10.1377/hlthaff.2012.0552
    
},
eprint = { 
        https://doi.org/10.1377/hlthaff.2012.0552
    
}
,
    abstract = { The Affordable Care Act enables young adults to remain as dependents on their parents’ health insurance until age twenty-six, and recent evidence suggests that as many as three million young adults have gained coverage as a result. However, there has been no evidence yet on the policy’s effect on access to care, and questions remain about the coverage impact on important subgroups. Using data from two nationally representative surveys, comparing young adults who gained access to dependent coverage to a control group (adults ages 26–34) who were not affected by the new policy, we found sizable coverage gains for adults ages 19–25. The gains continued to grow throughout 2011 (up 6.7 percentage points from September 2010 to September 2011), with the largest gains seen in unmarried adults, nonstudents, and men. Analysis of the timing of the policy impact suggested that early gains in coverage were greatest for people in worse health. We found strong evidence of increased access to care because of the law, with significant reductions in the number of young adults who delayed getting care and in those who did not receive needed care because of cost. }
}

@techreport{heberleinHoldingSteadyLooking2011,
  title = {Holding Steady, Looking Ahead: {{Annual}} Findings of a 50-State Survey of Eligibility Rules, Enrollment and Renewal Procedures, and Cost-Sharing Practices in {{Medicaid}} and {{CHIP}}, 2010\textendash 2011},
  author = {Heberlein, Martha and Brooks, Tricia and Guyer, Jocelyn and Artiga, Samantha and Stephens, Jessica},
  year = {2011},
  institution = {{Kaiser Commission on Medicaid and the Uninsured}}
}

@misc{alma9983557296402771,
abstract = {<p>The IowaCare program is a limited-benefit, public health insurance program for Iowa adults with income that does not exceed 200% of the federal poverty level.  It was authorized by Iowa House File 841 under a Medicaid expansion program and approved on July 1, 2005.  This program covers some inpatient and outpatient services, physician, and advanced registered nurse practitioner services, limited dental services, routine yearly physicals, smoking cessation, and limited prescription drug benefits.  The program was created, in part, to fill the gap in adult health care coverage that was expected to occur from the loss of the Iowa Indigent Care Program (a.k.a. the State Papers Program).   The 2010 Iowa Legislature modified the program so that an IowaCare Medical Home pilot project was started on October 1, 2010, in part, to prepare for what was expected to be an influx of new Medicaid enrollees in 2014 resulting from the Medicaid expansion component of the Patient Protection and Affordable Care Act (ACA). The IowaCare 1115 waiver will expire on December 31, 2013. As of June 2013, the Iowa Legislature passed the Iowa Health and Wellness Plan that will provide coverage to existing IowaCare members through a combination of an expansion of Medicaid with a slightly different benefit package, based on that of Iowa State Employees, and the purchase of subsidized insurance on the forthcoming Health Insurance Exchanges.   This report evaluates a variety of aspects of the IowaCare program from the perspective of the consumer. Enrollee perceptions of the IowaCare program were evaluated using mailed surveys with a sample of current IowaCare enrollees. A companion report evaluates outcomes of care for IowaCare enrollees using Medicaid claims and enrollment data.</p>},
author = {Peter C. Damiano and Bentler, Suzanne E. and  and Robinson, Erin and Park, Ki H. and Momany, Elizabeth T.},
address = {Iowa City, Iowa},
keywords = {Medicine and Health Sciences},
language = {eng},
pages = {234 pages},
publisher = {University of Iowa Public Policy Center},
title = {Evaluation of the IowaCare Program: Information about the Medical Home Expansion},
year = {2013}
}


@article{kaiserfamilyfoundationStatusStateAction2018,
  title = {Status of {{State Action}} on the {{Medicaid Expansion Decision}}},
  author = {{Kaiser Family Foundation}},
  year = {2018}
}
@article{louq.moghtaderiImpactMedicaidExpansion2018,
  title = {Impact of {{Medicaid Expansion}} on {{Total Revenue}} of {{Community Health Centers}} by {{Funding Sources}}},
  author = {Lou, Moghtaderi and Markus, A. and Dor, A.}, 
  year = {2018}
}

@techreport{NBERw25568,
 title = "The Effect of Health Insurance on Mortality:  Power Analysis and What We Can Learn from the Affordable Care Act Coverage Expansions",
 author = "Black, Bernard and Hollingsworth, Alex and Nunes, Leticia and Simon, Kosali",
 institution = "National Bureau of Economic Research",
 type = "Working Paper",
 series = "Working Paper Series",
 number = "25568",
 year = "2019",
 month = "February",
 doi = {10.3386/w25568},
 URL = "http://www.nber.org/papers/w25568",
 abstract = {A large literature examines the effect of health insurance on mortality. We contribute by emphasizing two challenges in using the Affordable Care Act (ACA)’s quasi-experimental variation to study mortality. The first is non-parallel pretreatment trends. Rising mortality in Medicaid non-expansion relative to expansion states prior to Medicaid expansion makes it difficult to estimate the effect of insurance using difference-in-differences (DD). We use various DD, triple difference, age-discontinuity and synthetic control approaches, but are unable to satisfactorily address this concern. Our estimates are not statistically significant, but are imprecise enough to be consistent with both no effect and a large effect of insurance on amenable mortality over the first three post-ACA years. Thus, our results should not be interpreted as evidence that health insurance has no effect on mortality for this age group, especially in light of the literature documenting greater health care use as a result of the ACA. Second, we provide a simulation-based power analysis, showing that even the nationwide natural experiment provided by the ACA is underpowered to detect plausibly sized mortality effects in available datasets, and discuss data needs for the literature to advance. Our simulated pseudo-shocks power analysis approach is broadly applicable to other natural-experiment studies.},
}
@article{simonImpactHealthInsurance2017,
  ids = {simonImpactHealthInsurance},
  title = {The {{Impact}} of {{Health Insurance}} on {{Preventive Care}} and {{Health Behaviors}}: {{Evidence}} from the {{First Two Years}} of the {{ACA Medicaid Expansions}}: {{Impact}} of {{Health Insurance}} on {{Preventive Care}} and {{Health Behaviors}}},
  shorttitle = {The {{Impact}} of {{Health Insurance}} on {{Preventive Care}} and {{Health Behaviors}}},
  author = {Simon, Kosali and Soni, Aparna and Cawley, John},
  year = {2017},
  month = mar,
  volume = {36},
  pages = {390--417},
  issn = {02768739},
  doi = {10/gdz4q9},
  file = {/Users/hollina/Zotero/storage/AXY9KGJM/Simon et al. - The Impact of Health Insurance on Preventive Care .pdf},
  journal = {Journal of Policy Analysis and Management},
  language = {en},
  number = {2}
}



@article{wherryEarlyCoverageAccess2016,
  title = {Early {{Coverage}}, {{Access}}, {{Utilization}}, and {{Health Effects Associated With}} the {{Affordable Care Act Medicaid Expansions}}: {{A Quasi}}-Experimental {{Study}}},
  shorttitle = {Early {{Coverage}}, {{Access}}, {{Utilization}}, and {{Health Effects Associated With}} the {{Affordable Care Act Medicaid Expansions}}},
  author = {Wherry, Laura R. and Miller, Sarah},
  year = {2016},
  month = jun,
  volume = {164},
  pages = {795},
  issn = {0003-4819},
  doi = {10/f8tz33},
  abstract = {Background\textemdash In 2014, only 26 states and D.C. chose to implement the Affordable Care Act (ACA) Medicaid expansions for low-income adults.},
  file = {/Users/hollina/Zotero/storage/9RCDVSHE/Wherry and Miller - 2016 - Early Coverage, Access, Utilization, and Health Ef.pdf},
  journal = {Annals of Internal Medicine},
  language = {en},
  number = {12}
}

@article{polskyAppointmentAvailabilityIncreases2015,
  title = {Appointment {{Availability}} after {{Increases}} in {{Medicaid Payments}} for {{Primary Care}}},
  author = {Polsky, Daniel and Richards, Michael and Basseyn, Simon and Wissoker, Douglas and Kenney, Genevieve M. and Zuckerman, Stephen and Rhodes, Karin V.},
  year = {2015},
  month = feb,
  volume = {372},
  pages = {537--545},
  issn = {0028-4793, 1533-4406},
  doi = {10/f6x37t},
  abstract = {Background Providing increases in Medicaid reimbursements for primary care, a key provision of the Affordable Care Act (ACA), raised Medicaid payments to Medicare levels in 2013 and 2014 for selected services and providers. The federally funded increase in reimbursements was aimed at expanding access to primary care for the growing number of Medicaid enrollees. The reimbursement increase expired at the end of 2014 in most states before policymakers had much empirical evidence about its effects. Methods We measured the availability of and waiting times for appointments in 10 states during two periods: from November 2012 through March 2013 and from May 2014 through July 2014. Trained field staff posed as either Medicaid enrollees or privately insured enrollees seeking new-patient primary care appointments. We estimated state-level changes over time in a stable cohort of primary care practices that participated in Medicaid to assess whether willingness to provide appointments for new Medicaid enrollees was related to the size of increases in Medicaid reimbursements in each state. From the Perelman School of Medicine (D.P., S.B., K.V.R.) and the Leonard Davis Institute of Health Economics (D.P., M.R., K.V.R.), University of Pennsylvania, Philadelphia; and the Urban Institute, Washington, DC (D.W., G.M.K., S.Z.). Address reprint requests to Dr. Polsky at the Leonard Davis Institute of Health Economics, University of Pennsylvania, 3641 Locust Walk, Suite 210, Philadelphia, PA 19104, or at polsky@wharton .upenn.edu. This article was published on January 21, 2015, at NEJM.org. N Engl J Med 2015;372:537-45. DOI: 10.1056/NEJMsa1413299 Copyright \textcopyright{} 2015 Massachusetts Medical Society. Results The availability of primary care appointments in the Medicaid group increased by 7.7 percentage points, from 58.7\% to 66.4\%, between the two time periods. The states with the largest increases in availability tended to be those with the largest increases in reimbursements, with an estimated increase of 1.25 percentage points in availability per 10\% increase in Medicaid reimbursements (P\,=\,0.03). No such association was observed in the private-insurance group. During the same periods, waiting times to a scheduled new-patient appointment remained stable over time in the two study groups. Conclusions Our study provides early evidence that increased Medicaid reimbursement to primary care providers, as mandated in the ACA, was associated with improved appointment availability for Medicaid enrollees among participating providers without generating longer waiting times. (Funded by the Robert Wood Johnson Foundation.)},
  file = {/Users/hollina/Zotero/storage/PW48MP4G/Polsky et al. - 2015 - Appointment Availability after Increases in Medica.pdf},
  journal = {New England Journal of Medicine},
  language = {en},
  number = {6}
}

@article {Case15078,
	author = {Case, Anne and Deaton, Angus},
	title = {Rising morbidity and mortality in midlife among white non-Hispanic Americans in the 21st century},
	volume = {112},
	number = {49},
	pages = {15078--15083},
	year = {2015},
	doi = {10.1073/pnas.1518393112},
	publisher = {National Academy of Sciences},
	abstract = {Midlife increases in suicides and drug poisonings have been previously noted. However, that these upward trends were persistent and large enough to drive up all-cause midlife mortality has, to our knowledge, been overlooked. If the white mortality rate for ages 45-54 had held at their 1998 value, 96,000 deaths would have been avoided from 1999{\textendash}2013, 7,000 in 2013 alone. If it had continued to decline at its previous (1979-1998) rate, half a million deaths would have been avoided in the period 1999-2013, comparable to lives lost in the US AIDS epidemic through mid-2015. Concurrent declines in self-reported health, mental health, and ability to work, increased reports of pain, and deteriorating measures of liver function all point to increasing midlife distress.This paper documents a marked increase in the all-cause mortality of middle-aged white non-Hispanic men and women in the United States between 1999 and 2013. This change reversed decades of progress in mortality and was unique to the United States; no other rich country saw a similar turnaround. The midlife mortality reversal was confined to white non-Hispanics; black non-Hispanics and Hispanics at midlife, and those aged 65 and above in every racial and ethnic group, continued to see mortality rates fall. This increase for whites was largely accounted for by increasing death rates from drug and alcohol poisonings, suicide, and chronic liver diseases and cirrhosis. Although all education groups saw increases in mortality from suicide and poisonings, and an overall increase in external cause mortality, those with less education saw the most marked increases. Rising midlife mortality rates of white non-Hispanics were paralleled by increases in midlife morbidity. Self-reported declines in health, mental health, and ability to conduct activities of daily living, and increases in chronic pain and inability to work, as well as clinically measured deteriorations in liver function, all point to growing distress in this population. We comment on potential economic causes and consequences of this deterioration.},
	issn = {0027-8424},
	URL = {https://www.pnas.org/content/112/49/15078},
	eprint = {https://www.pnas.org/content/112/49/15078.full.pdf},
	journal = {Proceedings of the National Academy of Sciences}
}


@techreport{kowalskiReconcilingSeeminglyContradictory2018a,
  title = {Reconciling {{Seemingly Contradictory Results}} from the {{Oregon Health Insurance Experiment}} and the {{Massachusetts Health Reform}}},
  author = {Kowalski, Amanda},
  year = {2020},
  month = may,
  pages = {w24647},
  address = {{Cambridge, MA}},
  institution = {{National Bureau of Economic Research}},
  doi = {10.3386/w24647},
  abstract = {A headline result from the Oregon Health Insurance Experiment is that emergency room (ER) utilization increased. A seemingly contradictory result from the Massachusetts health reform is that ER utilization decreased. I reconcile both results by identifying treatment effect heterogeneity within the Oregon experiment and extrapolating it to Massachusetts. Even though Oregon compliers increased their ER utilization, they were adversely selected relative to Oregon never takers, who would have decreased their ER utilization. Massachusetts expanded coverage from a higher level to healthier compliers. Therefore, Massachusetts compliers are comparable to a subset of Oregon never takers, which can reconcile the results.},
  file = {/Users/hollina/Zotero/storage/5PM2LJDL/Kowalski - 2018 - Reconciling Seemingly Contradictory Results from t.pdf},
  language = {en},
  number = {w24647}
}


@article{kenneyVariationMedicaidEligibility2012,
  title = {Variation in {{Medicaid Eligibility}} and {{Participation}} among {{Adults}}: {{Implications}} for the {{Affordable Care Act}}},
  shorttitle = {Variation in {{Medicaid Eligibility}} and {{Participation}} among {{Adults}}},
  author = {Kenney, Genevieve M. and Lynch, Victoria and Haley, Jennifer and Huntress, Michael},
  year = {2012},
  month = aug,
  volume = {49},
  pages = {231--253},
  issn = {0046-9580, 1945-7243},
  doi = {10/f4fk2q},
  file = {/Users/hollina/Zotero/storage/78QLSQHN/Kenney et al. - 2012 - Variation in Medicaid Eligibility and Participatio.pdf;/Users/hollina/Zotero/storage/SY3URXAT/Kenney et al. - 2012 - Variation in Medicaid Eligibility and Participatio.pdf},
  journal = {Inquiry},
  language = {en},
  number = {3}
}



@article{borgschulteDidACAMedicaid2020,
  title = {Did the {{ACA Medicaid}} Expansion Save Lives?},
  author = {Borgschulte, Mark and Vogler, Jacob},
  year = {2020},
  month = jul,
  volume = {72},
  pages = {102333},
  issn = {01676296},
  doi = {10/gg88gz},
  file = {/Users/hollina/Zotero/storage/YM2D9FE9/Borgschulte and Vogler - 2020 - Did the ACA Medicaid expansion save lives.pdf},
  journal = {Journal of Health Economics},
  language = {en}
}

@article{dunnDoesMedicarePart2019,
  title = {Does {{Medicare Part D Save Lives}}?},
  author = {Dunn, Abe and Shapiro, Adam Hale},
  year = {2019},
  month = jan,
  volume = {5},
  pages = {126--164},
  issn = {2332-3493, 2332-3507},
  doi = {10/gdz4sf},
  abstract = {We examine the impact of Medicare Part D on mortality for the population over the age of 65. We identify the effects of the reform using variation in drug coverage across counties before the reform was implemented. Studying mortality rates immediately before and after the reform, we find that cardiovascular-related mortality drops significantly in those counties most affected by Part D. Estimates suggest that up to 26,000 more individuals were alive in mid-2007 because of the Part D implementation in 2006. We estimate the welfare benefit from lives saved to range from \$1.5 to \$4.8 billion.},
  file = {/Users/hollina/Zotero/storage/G8ZQWDRH/Dunn and Shapiro - 2019 - Does Medicare Part D Save Lives.pdf},
  journal = {American Journal of Health Economics},
  language = {en},
  number = {1}
}

@article{goldinHealthInsuranceMortality2021,
  title = {Health {{Insurance}} and {{Mortality}}: {{Experimental Evidence}} from {{Taxpayer Outreach}}},
  author = {Goldin, Jacob and Lurie, Ithai Z and McCubbin, Janet},
  year = {2021},
  pages = {53},
  file = {/Users/hollina/Zotero/storage/I8XVPZJA/Goldin et al. - HEALTH INSURANCE AND MORTALITY EXPERIMENTAL EVIDE.pdf},
  journal = {Quarterly Journal of Economics},
  keywords = {❓ Multiple DOI},
  language = {en}
}

@article{mcclellanAffordableCareAct2017a,
  title = {The {{Affordable Care Act}}'s {{Dependent Care Coverage}} and {{Mortality}}},
  author = {McClellan, Chandler},
  year = {2017},
  volume = {55},
  pages = {6},
  doi = {10/f97vzk},
  abstract = {Background: In September 2010, the Affordable Care Act (ACA) enabled young adults to gain insurance coverage under their parents' policies. Objective: Assess the impact of the ACA's dependent care coverage expansion on young adult mortality rates. Research Design: Using the Multiple Cause Mortality public use database for 2008\textendash 2013, the impact of the ACA is examined with a difference-in-differences analysis of monthly mortality rates using individuals aged 26\textendash 30 as a natural control group for young adults aged 19\textendash 25. Results: The average monthly disease-related mortality rate of the 19\textendash 25 years old group fell by between 3.1\% and 6.1\% in the wake of the dependent care coverage expansion. Reduction in mortality was primarily in disease-related causes which are amenable to general medical care such as cardiovascular disease, while mortality due to trauma-related causes, which must be treated regardless of insurance status under preexisting laws, was unaffected. Conclusion: The reduction in mortality from this single provision of the ACA indicates that larger gains in preventable mortality could be made as health insurance coverage continues to expand under the ACA.},
  file = {/Users/hollina/Zotero/storage/ZM7Z2XIT/McClellan - 2017 - The Affordable Care Act’s Dependent Care Coverage .pdf},
  journal = {Medical Care},
  language = {en},
  number = {5}
}


@article{millerMedicaidMortalityNew2019,
  title = {Medicaid and {{Mortality}}: {{New Evidence}} from {{Linked Survey}} and {{Administrative Data}}},
  shorttitle = {Medicaid and {{Mortality}}},
  author = {Miller, Sarah and Johnson, Norman and Wherry, Laura},
  year = {2021},
   volume = {136},
  pages = {1783-1829},
    journal = {The Quarterly Journal of Economics},
  language = {en},
}



@article{powellImperfectSyntheticControlsc,
  title = {Imperfect {{Synthetic Controls}}: {{Did}} the {{Massachusetts Health Care Reform Save Lives}}?},
  author = {Powell, David},
  pages = {44},
  year = {2018},
  abstract = {The synthetic control method has become a valuable and widely-used technique to estimate causal effects even when more traditional fixed effects methods are inappropriate. This paper relaxes two critical assumptions required to implement the synthetic control estimator. First, the synthetic control estimator assumes that the outcomes of the treated unit are within the ``convex hull'' of the outcomes of the untreated units. In this paper, I show that estimation of the policy effect is possible when the treated unit composes part of the synthetic control for any of the untreated units, permitting the treated unit to be outside the convex hull of the other units. Instead of constructing a synthetic control only for the treated unit, this paper recommends creating a synthetic control for every unit. The difference in the post-treatment outcomes for each unit compared to its synthetic control is related to the corresponding difference in the policy variable, identifying the policy effect. Second, the synthetic control estimator assumes the existence of a ``perfect'' synthetic control, which only occurs if the outcome variable is not subject to transitory shocks. In this paper, I suggest a straightforward two-step approach which first generates predicted values of the outcome variables for each unit and uses these predicted values instead of the actual values of the outcome variable when constructing the synthetic control units. Together, these two modifications significantly reduce the restrictions imposed by the synthetic control estimator and provide asymptotically unbiased estimates of the policy effect. Simulations show that this approach outperforms the traditional synthetic control estimator. I apply the new estimator to study the mortality effects of the 2006 Massachusetts Health Care Reform and estimate that the reform reduced the mortality rate by 3\%.},
  file = {/Users/hollina/Zotero/storage/YDIIQM7L/Powell - Imperfect Synthetic Controls Did the Massachusett.pdf},
  keywords = {❓ Multiple DOI},
  language = {en}
}

@article{sommersChangesMortalityMassachusetts2014,
  ids = {sommersChangesMortalityMassachusettsa},
  title = {Changes in {{Mortality After Massachusetts Health Care Reform}}: {{A Quasi}}-Experimental {{Study}}},
  shorttitle = {Changes in {{Mortality After Massachusetts Health Care Reform}}},
  author = {Sommers, Benjamin D. and Long, Sharon K. and Baicker, Katherine},
  year = {2014},
  month = may,
  volume = {160},
  pages = {585},
  issn = {0003-4819},
  doi = {10/bkxh},
  file = {/Users/hollina/Zotero/storage/B6NMAR8Z/Sommers et al_2014_Changes in Mortality After Massachusetts Health Care Reform.pdf;/Users/hollina/Zotero/storage/QPMQ7L3I/Sommers et al. - Changes in Mortality After Massachusetts Health Ca.pdf},
  journal = {Annals of Internal Medicine},
  keywords = {⛔ No DOI found},
  language = {en},
  number = {9}
}

@article{sommersMortalityAccessCare2012,
  title = {Mortality and {{Access}} to {{Care}} among {{Adults}} after {{State Medicaid Expansions}}},
  author = {Sommers, Benjamin D. and Baicker, Katherine and Epstein, Arnold M.},
  year = {2012},
  month = sep,
  volume = {367},
  pages = {1025--1034},
  issn = {0028-4793, 1533-4406},
  doi = {10/6dw},
  abstract = {Background Several states have expanded Medicaid eligibility for adults in the past decade, and the Affordable Care Act allows states to expand Medicaid dramatically in 2014. Yet the effect of such changes on adults' health remains unclear. We examined whether Medicaid expansions were associated with changes in mortality and other healthrelated measures. Methods We compared three states that substantially expanded adult Medicaid eligibility since 2000 (New York, Maine, and Arizona) with neighboring states without expansions. The sample consisted of adults between the ages of 20 and 64 years who were observed 5 years before and after the expansions, from 1997 through 2007. The primary outcome was all-cause county-level mortality among 68,012 year- and countyspecific observations in the Compressed Mortality File of the Centers for Disease Control and Prevention. Secondary outcomes were rates of insurance coverage, delayed care because of costs, and self-reported health among 169,124 persons in the Current Population Survey and 192,148 persons in the Behavioral Risk Factor Surveillance System. From the Department of Health Policy and Management, Harvard School of Public Health, Boston. Address reprint requests to Dr. Sommers at the Department of Health Policy and Management, Harvard School of Public Health, 677 Huntington Ave., Rm. 406, Boston, MA 02115, or at bsommers@hsph.harvard.edu. This article was published on July 25, 2012, at NEJM.org. N Engl J Med 2012;367:1025-34. DOI: 10.1056/NEJMsa1202099 Copyright \textcopyright{} 2012 Massachusetts Medical Society. Results Medicaid expansions were associated with a significant reduction in adjusted allcause mortality (by 19.6 deaths per 100,000 adults, for a relative reduction of 6.1\%; P\,=\,0.001). Mortality reductions were greatest among older adults, nonwhites, and residents of poorer counties. Expansions increased Medicaid coverage (by 2.2 percentage points, for a relative increase of 24.7\%; P\,=\,0.01), decreased rates of uninsurance (by 3.2 percentage points, for a relative reduction of 14.7\%; P{$<$}0.001), decreased rates of delayed care because of costs (by 2.9 percentage points, for a relative reduction of 21.3\%; P\,=\,0.002), and increased rates of self-reported health status of ``excellent'' or ``very good'' (by 2.2 percentage points, for a relative increase of 3.4\%; P\,=\,0.04). Conclusions State Medicaid expansions to cover low-income adults were significantly associated with reduced mortality as well as improved coverage, access to care, and selfreported health.},
  file = {/Users/hollina/Zotero/storage/7TE9BFJY/Sommers et al. - 2012 - Mortality and Access to Care among Adults after St.pdf},
  journal = {New England Journal of Medicine},
  language = {en},
  number = {11}
}



@article{baickerOregonExperimentEffects2013,
  title = {The {{Oregon Experiment}} \textemdash{} {{Effects}} of {{Medicaid}} on {{Clinical Outcomes}}},
  author = {Baicker, Katherine and Taubman, Sarah L. and Allen, Heidi L. and Bernstein, Mira and Gruber, Jonathan H. and Newhouse, Joseph P. and Schneider, Eric C. and Wright, Bill J. and Zaslavsky, Alan M. and Finkelstein, Amy N.},
  year = {2013},
  month = may,
  volume = {368},
  pages = {1713--1722},
  issn = {0028-4793, 1533-4406},
  doi = {10/f4wdzx},
  abstract = {Background Despite the imminent expansion of Medicaid coverage for low-income adults, the effects of expanding coverage are unclear. The 2008 Medicaid expansion in Oregon based on lottery drawings from a waiting list provided an opportunity to evaluate these effects. Methods Approximately 2 years after the lottery, we obtained data from 6387 adults who were randomly selected to be able to apply for Medicaid coverage and 5842 adults who were not selected. Measures included blood-pressure, cholesterol, and glycated hemoglobin levels; screening for depression; medication inventories; and self-reported diagnoses, health status, health care utilization, and out-of-pocket spending for such services. We used the random assignment in the lottery to calculate the effect of Medicaid coverage. Results We found no significant effect of Medicaid coverage on the prevalence or diagnosis of hypertension or high cholesterol levels or on the use of medication for these conditions. Medicaid coverage significantly increased the probability of a diagnosis of diabetes and the use of diabetes medication, but we observed no significant effect on average glycated hemoglobin levels or on the percentage of participants with levels of 6.5\% or higher. Medicaid coverage decreased the probability of a positive screening for depression (-9.15 percentage points; 95\% confidence interval, -16.70 to -1.60; P\,=\,0.02), increased the use of many preventive services, and nearly eliminated catastrophic out-of-pocket medical expenditures. From the Department of Health Policy and Management, Harvard School of Public Health (K.B., J.P.N., E.C.S.), the Department of Health Care Policy, Harvard Medical School (J.P.N., E.C.S., A.M.Z.), and RAND Corporation (E.C.S.) \textemdash{} all in Boston; the National Bureau of Economic Research (K.B., S.L.T., M.B., J.H.G., J.P.N., A.N.F.), the Harvard Kennedy School (J.P.N.), and the Department of Economics, Massachusetts Institute of Technology (J.H.G., A.N.F.) \textemdash{} all in Cambridge, MA; Columbia University School of Social Work, New York (H.L.A.); and the Center for Outcomes Research and Education, Providence Portland Medical Center, Portland, OR (B.J.W.). Address reprint requests to Dr. Baicker at the Department of Health Policy and Management, Harvard School of Public Health, 677 Huntington Ave., Boston, MA 02115, or at kbaicker@hsph.harvard.edu. *Members of the Oregon Health Study Group are listed in the Supplementary Appendix, available at NEJM.org. N Engl J Med 2013;368:1713-22. DOI: 10.1056/NEJMsa1212321 Copyright \textcopyright{} 2013 Massachusetts Medical Society. Conclusions This randomized, controlled study showed that Medicaid coverage generated no significant improvements in measured physical health outcomes in the first 2 years, but it did increase use of health care services, raise rates of diabetes detection and management, lower rates of depression, and reduce financial strain.},
  file = {/Users/hollina/Zotero/storage/DJQD5HBH/Baicker et al. - 2013 - The Oregon Experiment — Effects of Medicaid on Cli.pdf},
  journal = {New England Journal of Medicine},
  language = {en},
  number = {18}
}

@article{weathersEffectExpandingAccess2012,
  title = {The Effect of Expanding Access to Health Insurance on the Health and Mortality of {{Social Security Disability Insurance}} Beneficiaries},
  author = {Weathers, Robert R. and Stegman, Michelle},
  year = {2012},
  month = dec,
  volume = {31},
  pages = {863--875},
  issn = {01676296},
  doi = {10/f4f5c5},
  file = {/Users/hollina/Zotero/storage/EGKUETVE/Weathers and Stegman - 2012 - The effect of expanding access to health insurance.pdf},
  journal = {Journal of Health Economics},
  language = {en},
  number = {6}
}




@article{finkelsteinOregonHealthInsurance2012c,
  title = {The {{Oregon Health Insurance Experiment}}: {{Evidence}} from the {{First Year}}},
  shorttitle = {The {{Oregon Health Insurance Experiment}}},
  author = {Finkelstein, Amy and Taubman, Sarah and Wright, Bill and Bernstein, Mira and Gruber, Jonathan and Newhouse, Joseph P. and Allen, Heidi and Baicker, Katherine and {Oregon Health Study Group}},
  year = {2012},
  month = aug,
  volume = {127},
  pages = {1057--1106},
  issn = {0033-5533, 1531-4650},
  doi = {10.1093/qje/qjs020},
  abstract = {Abstract             In 2008, a group of uninsured low-income adults in Oregon was selected by lottery to be given the chance to apply for Medicaid. This lottery provides an opportunity to gauge the effects of expanding access to public health insurance on the health care use, financial strain, and health of low-income adults using a randomized controlled design. In the year after random assignment, the treatment group selected by the lottery was about 25 percentage points more likely to have insurance than the control group that was not selected. We find that in this first year, the treatment group had substantively and statistically significantly higher health care utilization (including primary and preventive care as well as hospitalizations), lower out-of-pocket medical expenditures and medical debt (including fewer bills sent to collection), and better self-reported physical and mental health than the control group.},
  file = {/Users/hollina/Zotero/storage/9PBKDSVA/Finkelstein et al. - 2012 - The Oregon Health Insurance Experiment Evidence f.pdf},
  journal = {The Quarterly Journal of Economics},
  language = {en},
  number = {3}
}

@article{cardDoesMedicareLives2009,
  ids = {cardDOESMEDICARELIVES},
  title = {Does {{Medicare Save Lives}}?},
  shorttitle = {Does {{Medicare Save Lives}}?},
  author = {Card, David and Dobkin, Carlos and Maestas, Nicole},
  year = {2009},
  month = may,
  volume = {124},
  pages = {597--636},
  issn = {0033-5533, 1531-4650},
  doi = {10/dxjv2f},
  file = {/Users/hollina/Zotero/storage/3DVRTKET/Card et al_2009_Does Medicare Save Lives.pdf;/Users/hollina/Zotero/storage/Y3AAJPYQ/Card et al. - DOES MEDICARE SAVE LIVES.pdf},
  journal = {Quarterly Journal of Economics},
  keywords = {⛔ No DOI found},
  language = {en},
  number = {2}
}

@techreport{cardImpactNearlyUniversal2004,
  title = {The {{Impact}} of {{Nearly Universal Insurance Coverage}} on {{Health Care Utilization}} and {{Health}}: {{Evidence}} from {{Medicare}}},
  shorttitle = {The {{Impact}} of {{Nearly Universal Insurance Coverage}} on {{Health Care Utilization}} and {{Health}}},
  author = {Card, David and Dobkin, Carlos and Maestas, Nicole},
  year = {2004},
  month = mar,
  pages = {w10365},
  address = {{Cambridge, MA}},
  institution = {{National Bureau of Economic Research}},
  doi = {10.3386/w10365},
  file = {/Users/hollina/Zotero/storage/9Y7YHP5A/Card et al_2004_The Impact of Nearly Universal Insurance Coverage on Health Care Utilization.pdf;/Users/hollina/Zotero/storage/RBWT6I53/w10365.pdf},
  language = {en},
  number = {w10365}
}

@article{cardImpactNearlyUniversal2008c,
  title = {The {{Impact}} of {{Nearly Universal Insurance Coverage}} on {{Health Care Utilization}}: {{Evidence}} from {{Medicare}}},
  shorttitle = {The {{Impact}} of {{Nearly Universal Insurance Coverage}} on {{Health Care Utilization}}},
  author = {Card, David and Dobkin, Carlos and Maestas, Nicole},
  year = {2008},
  month = nov,
  volume = {98},
  pages = {2242--2258},
  issn = {0002-8282},
  doi = {10/b38h43},
  abstract = {The onset of Medicare eligibility at age 65 leads to sharp changes in the health insurance coverage of the US population. These changes lead to increases in the use of medical services, with a pattern of gains across socioeconomic groups that varies by type of service. While routine doctor visits increase more for groups that previously lacked insurance, hospital admissions for relatively expensive procedures like bypass surgery and joint replacement increase more for previously insured groups that are more likely to have supplementary coverage after 65, reflecting the relative generosity of their combined insurance package under Medicare. (JEL I11, I18)},
  file = {/Users/hollina/Zotero/storage/E35HAU9U/Card et al. - 2008 - The Impact of Nearly Universal Insurance Coverage .pdf},
  journal = {American Economic Review},
  language = {en},
  number = {5}
}

@article{doyleHealthInsuranceTreatment2005,
  ids = {doyleHealthInsuranceTreatment},
  title = {Health {{Insurance}}, {{Treatment}} and {{Outcomes}}: {{Using Auto Accidents}} as {{Health Shocks}}},
  shorttitle = {Health {{Insurance}}, {{Treatment}} and {{Outcomes}}},
  author = {Doyle, Joseph J.},
  year = {2005},
  month = may,
  volume = {87},
  pages = {256--270},
  issn = {0034-6535, 1530-9142},
  doi = {10/fvnwwb},
  file = {/Users/hollina/Zotero/storage/FBDPABWL/Doyle_2005_Health Insurance, Treatment and Outcomes.pdf;/Users/hollina/Zotero/storage/IZ9J2N4Z/Doyle - Health Insurance, Treatment and Outcomes Using Au.pdf},
  journal = {Review of Economics and Statistics},
  keywords = {⛔ No DOI found},
  language = {en},
  number = {2}
}

@article{levyImpactHealthInsurance2008,
  title = {The {{Impact}} of {{Health Insurance}} on {{Health}}},
  author = {Levy, Helen G. and Meltzer, David},
  year = {2008},
  month = apr,
  volume = {29},
  pages = {399--409},
  issn = {0163-7525, 1545-2093},
  doi = {10/dx82s4},
  abstract = {How does health insurance affect health? After reviewing the evidence on this question, we reach three conclusions. First, many of the studies claiming to show a causal effect of health insurance on health do not do so convincingly because the observed correlation between insurance and good health may be driven by other, unobservable factors. Second, convincing evidence demonstrates that health insurance can improve health measures of some population subgroups, some of which, although not all, are the same subgroups that would be the likely targets of coverage expansion policies. Third, for policy purposes we need to know whether the results of these studies generalize. Solid answers to the multitude of important questions about how specific health insurance policy options may affect health seem likely to be forthcoming only with investment of substantial resources in social experiments.},
  file = {/Users/hollina/Zotero/storage/DGT9QX83/Levy and Meltzer - 2008 - The Impact of Health Insurance on Health.pdf},
  journal = {Annual Review of Public Health},
  language = {en},
  number = {1}
}

@incollection{levyWhatWeReally2004,
  title = {What Do We Really Know about Whether Health Insurance Affects Health?},
  booktitle = {Health Policy and the Uninsured},
  author = {Levy, Helen G. and Meltzer, David},
  editor = {McLaughlin, Catherine G.},
  year = {2004},
  publisher = {{Urban Institute Press}},
  address = {{Washington, D.C}},
  isbn = {978-0-87766-719-3},
  keywords = {economics,Health insurance,Health Policy,Insurance; Health,Medical policy,Medically Uninsured,Medically uninsured persons,United States,Vulnerable Populations},
  lccn = {RA413.7.U53 H434 2004}
}



@article{brookDoesFreeCare1983,
  title = {Does {{Free Care Improve Adults}}' {{Health}}?: {{Results}} from a {{Randomized Controlled Trial}}},
  shorttitle = {Does {{Free Care Improve Adults}}' {{Health}}?},
  author = {Brook, Robert H. and Ware, John E. and Rogers, William H. and Keeler, Emmett B. and Davies, Allyson R. and Donald, Cathy A. and Goldberg, George A. and Lohr, Kathleen N. and Masthay, Patricia C. and Newhouse, Joseph P.},
  year = {1983},
  month = dec,
  volume = {309},
  pages = {1426--1434},
  issn = {0028-4793, 1533-4406},
  doi = {10/fpgzpt},
  file = {/Users/hollina/Zotero/storage/XM6SSQWX/Brook et al. - 1983 - Does Free Care Improve Adults' Health Results fr.pdf},
  journal = {New England Journal of Medicine},
  language = {en},
  number = {23}
}

@article{finkelsteinAggregateEffectsHealth2007,
  ids = {finkelsteinAg},
  title = {The {{Aggregate Effects}} of {{Health Insurance}}: {{Evidence}} from the {{Introduction}} of {{Medicare}}},
  shorttitle = {The {{Aggregate Effects}} of {{Health Insurance}}},
  author = {Finkelstein, A.},
  year = {2007},
  month = feb,
  volume = {122},
  pages = {1--37},
  issn = {0033-5533, 1531-4650},
  doi = {10/fqfkdt},
  file = {/Users/hollina/Zotero/storage/4XLMEVPG/Finkelstein - THE AGGREGATE EFFECTS OF HEALTH INSURANCE EVIDENC.pdf;/Users/hollina/Zotero/storage/UTJEMXFF/Finkelstein_2007_The Aggregate Effects of Health Insurance.pdf},
  journal = {The Quarterly Journal of Economics},
  keywords = {⛔ No DOI found},
  language = {en},
  number = {1}
}

@article{finkelsteinWhatDidMedicare2008,
  title = {What Did {{Medicare}} Do? {{The}} Initial Impact of {{Medicare}} on Mortality and out of Pocket Medical Spending},
  shorttitle = {What Did {{Medicare}} Do?},
  author = {Finkelstein, Amy and McKnight, Robin},
  year = {2008},
  month = jul,
  volume = {92},
  pages = {1644--1668},
  issn = {00472727},
  doi = {10/bzd2rx},
  abstract = {We study the impact of the introduction of one of the major pillars of the social insurance system in the United States: the introduction of Medicare in 1965. Our results suggest that, in its first 10 years, the establishment of universal health insurance for the elderly had no discernible impact on elderly mortality. However, we find a substantial reduction in the elderly's exposure to out of pocket medical expenditure risk. Specifically, we estimate that the introduction of Medicare was associated with a 40\% decline in out of pocket spending for the top quartile of the out of pocket spending distribution. A stylized expected utility framework suggests that the welfare gains from such reductions in risk exposure alone may be sufficient to cover almost two-fifths of the costs of Medicare. These findings underscore the importance of considering the direct insurance benefits from public health insurance programs, in addition to any indirect benefits from an effect on health.},
  file = {/Users/hollina/Zotero/storage/HVVRMBXS/Finkelstein and McKnight - 2008 - What did Medicare do The initial impact of Medica.pdf},
  journal = {Journal of Public Economics},
  language = {en},
  number = {7}
}

@article{keelerHowFreeCare1985,
  ids = {keelerHowFreeCare},
  title = {How Free Care Reduced Hypertension in the Health Insurance Experiment},
  author = {Keeler, E. B. and {Brook, Robert H.} and {Goldberg, George A.} and {Kamberg, Caren J.} and {Newhouse, Joseph P.}},
  year = {1985},
  month = oct,
  volume = {254},
  pages = {1926--1931},
  issn = {00987484, 15383598},
  doi = {10/bb57cs},
  file = {/Users/hollina/Zotero/storage/BKQSWPPE/Keeler et al. - How Free Care Reduced Hypertension in the Health I.pdf},
  journal = {JAMA: The Journal of the American Medical Association},
  keywords = {❓ Multiple DOI},
  number = {14}
}

@book{newhouseFreeAllLessons1993,
  title = {Free for All? Lessons from the {{Rand Health Insurance Experiment}}},
  shorttitle = {Free for All?},
  author = {Newhouse, Joseph P.},
  year = {1993},
  publisher = {{Harvard University Press}},
  address = {{Cambridge, Mass}},
  collaborator = {Rand Corporation},
  isbn = {978-0-674-31846-5},
  keywords = {Delivery of Health Care,economics,Health coinsurance,Health insurance,Health Status,Insurance; Health,Medical care,Medical care; Cost of,Rand Health Insurance Experiment,Research,United States,Utilization},
  lccn = {RA410.53 .N52 1993}
}






@article{gilbertMakingSenseMethods2016,
  title = {Making {{Sense}} of {{Methods}} and {{Measurement}}: {{The Danger}} of the {{Retrospective Power Analysis}}},
  shorttitle = {Making {{Sense}} of {{Methods}} and {{Measurement}}},
  author = {Gilbert, Gregory E. and Prion, Susan},
  year = {2016},
  month = aug,
  volume = {12},
  pages = {303--304},
  issn = {18761399},
  doi = {10/ghj6z2},
  file = {/Users/hollina/Zotero/storage/D435CSYI/Gilbert and Prion - 2016 - Making Sense of Methods and Measurement The Dange.pdf},
  journal = {Clinical Simulation in Nursing},
  language = {en},
  number = {8}
}



@article{gouveiaTimeSeriesAnalysis2000,
  title = {Time Series Analysis of Air Pollution and Mortality: Effects by Cause, Age and Socioeconomic Status},
  shorttitle = {Time Series Analysis of Air Pollution and Mortality},
  author = {Gouveia, Nelson and Fletcher, Tony},
  year = {2000},
  month = oct,
  volume = {54},
  pages = {750--755},
  issn = {0143005X},
  doi = {10.1136/jech.54.10.750},
  abstract = {Objective\textemdash To investigate the association between outdoor air pollution and mortality in Sa\texttildelow{} o Paulo, Brazil. Design\textemdash Time series study Methods\textemdash All causes, respiratory and cardiovascular mortality were analysed and the role of age and socioeconomic status in modifying associations between mortality and air pollution were investigated. Models used Poisson regression and included terms for temporal patterns, meteorology, and autocorrelation. Main results\textemdash All causes all ages mortality showed much smaller associations with air pollution than mortality for specific causes and age groups. In the elderly, a 3\textendash 4\% increase in daily deaths for all causes and for cardiovascular diseases was associated with an increase in fine particulate matter and in sulphur dioxide from the 10th to the 90th percentile. For respiratory deaths the increase in mortality was higher (6\%). Cardiovascular deaths were additionally associated with levels of carbon monoxide (4\% increase in daily deaths). The associations between air pollutants and mortality in children under 5 years of age were not statistically significant. There was a significant trend of increasing risk of death according to age with eVects most evident for subjects over 65 years old. The eVect of air pollution was also larger in areas of higher socioeconomic level. Conclusions\textemdash These results show further evidence of an association between air pollution and mortality but of smaller magnitude than found in other similar studies. In addition, it seems that older age groups are at a higher risk of mortality associated with air pollution. Such complexity should be taken into account in health risk assessment based on time series studies.},
  file = {/Users/hollina/Zotero/storage/UP5K57G9/Gouveia - 2000 - Time series analysis of air pollution and mortalit.pdf},
  journal = {Journal of Epidemiology \& Community Health},
  language = {en},
  number = {10}
}

@article{Burlig2019,
title = {Panel data and experimental design},
journal = {Journal of Development Economics},
volume = {144},
pages = {102458},
year = {2020},
issn = {0304-3878},
doi = {https://doi.org/10.1016/j.jdeveco.2020.102458},
url = {https://www.sciencedirect.com/science/article/pii/S030438782030033X},
author = {Fiona Burlig and Louis Preonas and Matt Woerman},
keywords = {Power, Experimental design, Panel data, Sample size},
abstract = {How should researchers design panel data experiments? We analytically derive the variance of panel estimators, informing power calculations in panel data settings. We generalize Frison and Pocock (1992) to fully arbitrary error structures, thereby extending McKenzie (2012) to allow for non-constant serial correlation. Using Monte Carlo simulations and real-world panel data, we demonstrate that failing to account for arbitrary serial correlation ex ante yields experiments that are incorrectly powered under proper inference. By contrast, our “serial-correlation-robust” power calculations achieve correctly powered experiments in both simulated and real data. We discuss the implications of these results, and introduce a new software package to facilitate proper power calculations in practice.}
}
@article{Arnold2011,
abstract = {Background: Estimating the required sample size and statistical power for a study is an integral part of study design. For standard designs, power equations provide an efficient solution to the problem, but they are unavailable for many complex study designs that arise in practice. For such complex study designs, computer simulation is a useful alternative for estimating study power. Although this approach is well known among statisticians, in our experience many epidemiologists and social scientists are unfamiliar with the technique. This article aims to address this knowledge gap. Methods. We review an approach to estimate study power for individual- or cluster-randomized designs using computer simulation. This flexible approach arises naturally from the model used to derive conventional power equations, but extends those methods to accommodate arbitrarily complex designs. The method is universally applicable to a broad range of designs and outcomes, and we present the material in a way that is approachable for quantitative, applied researchers. We illustrate the method using two examples (one simple, one complex) based on sanitation and nutritional interventions to improve child growth. Results: We first show how simulation reproduces conventional power estimates for simple randomized designs over a broad range of sample scenarios to familiarize the reader with the approach. We then demonstrate how to extend the simulation approach to more complex designs. Finally, we discuss extensions to the examples in the article, and provide computer code to efficiently run the example simulations in both R and Stata. Conclusions: Simulation methods offer a flexible option to estimate statistical power for standard and non-traditional study designs and parameters of interest. The approach we have described is universally applicable for evaluating study designs used in epidemiologic and social science research. {\textcopyright} 2011 Arnold et al; licensee BioMed Central Ltd.},
author = {Arnold, Benjamin F. and Hogan, Daniel R. and Colford, John M. and Hubbard, Alan E.},
doi = {10.1186/1471-2288-11-94},
file = {:Users/hollina/Documents/Mendeley Desktop/Arnold et al.{\_}2011{\_}Simulation methods to estimate design power An overview for applied research.pdf:pdf},
issn = {14712288},
journal = {BMC Medical Research Methodology},
keywords = {Computer Simulation,Power,Research Design,Sample Size},
mendeley-groups = {power{\_}analysis{\_}citations/power{\_}papers{\_}to{\_}read{\_}a{\_}second{\_}time},
title = {{Simulation methods to estimate design power: An overview for applied research}},
volume = {11},
year = {2011}
}
@article{Johnson2017b,
abstract = {Yahoo! Research partnered with a nationwide retailer to study the effects of online display advertising on both online and in-store purchases. We use a randomized field experiment on 3 million Yahoo! users who are also past customers of the retailer. We find statistically significant evidence that the retailer ads increase sales 3.6{\%} relative to the control group. We show that control ads boost measurement precision by identifying and removing the half of in-campaign sales data that are unaffected by the ads. Less data give us 31{\%} more precision in our estimates?equivalent to increasing our sample to 5.3 million users. By contrast, we only improve precision by 5{\%} when we include additional covariate data to reduce the residual variance in our experimental regression. The covariate-adjustment strategy disappoints despite exceptional consumer-level data including demographics, ad exposure levels, and two years' worth of past purchase history.},
author = {Johnson, Garrett A. and Lewis, Randall A. and Reiley, David H.},
doi = {10.1287/mksc.2016.0998},
file = {:Users/hollina/Documents/Mendeley Desktop/Johnson, Lewis, Reiley{\_}2017{\_}When less is more Data and power in advertising experiments.pdf:pdf},
issn = {1526548X},
journal = {Marketing Science},
keywords = {Advertising effectiveness,Digital advertising,Field experiments},
mendeley-groups = {power{\_}analysis{\_}citations/power{\_}papers{\_}to{\_}read{\_}a{\_}second{\_}time},
number = {1},
pages = {43--53},
title = {{When less is more: Data and power in advertising experiments}},
volume = {36},
year = {2017}
}
@article{Burlig2019a,
abstract = {How should researchers design panel data experiments? We analytically derive the variance of panel estimators, informing power calculations in panel data settings. We generalize Frison and Pocock (1992) to fully arbitrary error structures, thereby extending McKenzie (2012) to allow for non-constant serial correlation. Using Monte Carlo simulations and real world panel data, we demonstrate that failing to account for arbitrary serial correlation ex ante yields experiments that are incorrectly powered under proper inference. By contrast, our ?serial-correlation-robust? power calculations achieve correctly powered experiments in both simulated and real data. We discuss the implications of these results, and introduce a new software package to facilitate proper power calculations in practice.},
author = {Burlig, Fiona and Preonas, Louis and Woerman, Matt},
doi = {10.2139/ssrn.3450595},
file = {:Users/hollina/Documents/Mendeley Desktop/Burlig, Preonas, Woerman{\_}2019{\_}Panel Data and Experimental Design.pdf:pdf},
journal = {SSRN Electronic Journal},
mendeley-groups = {power{\_}analysis{\_}citations/power{\_}papers{\_}to{\_}read{\_}a{\_}second{\_}time},
pages = {1--76},
title = {{Panel Data and Experimental Design}},
year = {2019}
}
@article{Lewis2015,
abstract = {Twenty-five large field experiments with major U.S. retailers and brokerages, most reaching millions of customers and collectively representing {\$}2.8 million in digital advertising expenditure, reveal that measuring the returns to advertising is difficult. The median confidence interval on return on investment is over 100 percentage points wide. Detailed sales data show that relative to the per capita cost of the advertising, individual-level sales are very volatile; a coefficient of variation of 10 is common. Hence, informative advertising experiments can easily require more than 10 million person-weeks, making experiments costly and potentially infeasible for many firms. Despite these unfavorable economics, randomized control trials represent progress by injecting new, unbiased information into the market. The inference challenges revealed in the field experiments also show that selection bias, due to the targeted nature of advertising, is a crippling concern for widely employed observational methods.},
author = {Lewis, Randall A. and Rao, Justin M.},
doi = {10.1093/qje/qjv023},
file = {:Users/hollina/Documents/Mendeley Desktop/Lewis, Rao{\_}2015{\_}The unfavorable economics of measuring the returns to advertising(2).pdf:pdf},
issn = {15314650},
journal = {Quarterly Journal of Economics},
mendeley-groups = {power{\_}analysis{\_}citations/power{\_}papers{\_}to{\_}read{\_}a{\_}second{\_}time},
number = {4},
pages = {1941--1973},
title = {{The unfavorable economics of measuring the returns to advertising}},
volume = {130},
year = {2015}
}
@article{Bertrand2004,
abstract = {Copyright of Quarterly Journal of Economics is the property of MIT$\backslash$nPress and its content may not be copied or emailed to multiple sites$\backslash$nor posted to a listserv without the copyright holder's express written$\backslash$npermission. However, users may print, download, or email articles$\backslash$nfor individual use. This abstract may be abridged. No warranty is$\backslash$ngiven about the accuracy of the copy. Users should refer to the original$\backslash$npublished version of the material for the full abstract. (Copyright$\backslash$napplies to all Abstracts.)},
archivePrefix = {arXiv},
arxivId = {arXiv:gr-qc/9809069v1},
author = {Bertrand, Marianne and Duflo, Esther and Mullainathan, Sendhil},
doi = {10.1162/003355304772839588},
eprint = {9809069v1},
file = {:Users/hollina/Documents/Mendeley Desktop/Bertrand, Duflo, Mullainathan{\_}2004{\_}How Much Should We Trust Differences-In-Differences Estimates.pdf:pdf},
isbn = {00335533},
issn = {0033-5533},
journal = {The Quarterly Journal of Economics},
keywords = {ECONOMETRICS,ECONOMICS,MONTE Carlo method,STATISTICS},
mendeley-groups = {power{\_}analysis{\_}citations,power{\_}analysis{\_}citations/power{\_}papers{\_}to{\_}read{\_}a{\_}second{\_}time},
month = {feb},
number = {1},
pages = {249--275},
pmid = {18165480},
primaryClass = {arXiv:gr-qc},
title = {{How Much Should We Trust Differences-In-Differences Estimates?}},
url = {https://academic.oup.com/qje/article-lookup/doi/10.1162/003355304772839588},
volume = {119},
year = {2004}
}


@techreport{Anderson2017,
abstract = {Preanalysis plans (PAPs) have become an important tool for limiting false discoveries in field experiments. We evaluate the properties of an alternate approach which splits the data into two samples: An exploratory sample and a confirmation sample. When hypotheses are homogeneous, we describe an improved split-sample approach that achieves 90{\%} of the rejections of the optimal PAP without requiring preregistration or constraints on specification search in the exploratory sample. When hypotheses are heterogeneous in priors or intrinsic interest, we find that a hybrid approach which prespecifies hypotheses with high weights and priors and uses a split-sample approach to test additional hypotheses can have power gains over any pure PAP. We assess this approach using the community-driven development (CDD) application from Casey et al. (2012) and find that the use of a hybrid split-sample approach would have generated qualitatively different conclusions.},
address = {Cambridge, MA},
author = {Anderson, Michael and Magruder, Jeremy},
booktitle = {NBER Working Paper Series},
doi = {10.3386/w23544},
file = {:Users/hollinal/Documents/mendeley{\_}desktop/Anderson, Magruder{\_}2017.pdf:pdf},
institution = {National Bureau of Economic Research},
month = {jun},
number = {23544},
title = {{Split-Sample Strategies for Avoiding False Discoveries}},
url = {http://www.nber.org/papers/w23544.pdf},
year = {2017}
}
@article{Andreoni2013,
abstract = {Revealed preference tests are elegant nonparametric tools that ask whether choice data conforms to optimizing behavior. These tests present a vexing tension between goodness-of-fit and power. If the test finds violations, is there an acceptable tolerance for goodness-of-fit? If no violations are found, was the test demanding enough to be powerful? This paper complements the many on goodness-of-fit by presenting several new indices of power. By focusing on the underlying probability model induced by sampling, we attempt to unify the two approaches. We illustrate applications of the indices, and provide a field guide to applying them to experimental data.},
author = {Andreoni, James and Gillen, Benjamin J and Harbaugh, William T},
file = {:Users/hollinal/Documents/mendeley{\_}desktop/Andreoni, Gillen, Harbaugh{\_}2013.pdf:pdf},
journal = {Working paper},
title = {{The Power of Revealed Preference Tests: Ex-Post Evaluation of Experimental Design}},
year = {2013}
}
@article{Banerjee2015,
abstract = {Causal evidence on microcredit impacts informs theory, practice, and debates about its effectiveness as a development tool. The six randomized evaluations in this volume use a variety of sampling, data collection, experimental design, and econometric strategies to identify causal effects of expanded access to microcredit on borrowers and/or communities. These methods are deployed across an impressive range of locations—six countries on four continents, urban and rural areas—borrower characteristics, loan characteristics, and lender characteristics. Summarizing and interpreting results across studies, we note a consistent pattern of modestly positive, but not transformative, effects. We also discuss directions for future research. (JEL D14, G21, I38, O15, O16, P34, P36)},
author = {Banerjee, Abhijit and Karlan, Dean and Zinman, Jonathan},
doi = {10.1257/app.20140287},
file = {:Users/hollinal/Documents/mendeley{\_}desktop/Banerjee, Karlan, Zinman{\_}2015.pdf:pdf},
issn = {1945-7782},
journal = {American Economic Journal: Applied Economics},
keywords = {Causal evidence on microcredit impacts informs the},
month = {jan},
number = {1},
pages = {1--21},
title = {{Six Randomized Evaluations of Microcredit: Introduction and Further Steps}},
url = {http://pubs.aeaweb.org/doi/10.1257/app.20140287},
volume = {7},
year = {2015}
}
@article{Bertrand2004,
abstract = {Copyright of Quarterly Journal of Economics is the property of MIT$\backslash$nPress and its content may not be copied or emailed to multiple sites$\backslash$nor posted to a listserv without the copyright holder's express written$\backslash$npermission. However, users may print, download, or email articles$\backslash$nfor individual use. This abstract may be abridged. No warranty is$\backslash$ngiven about the accuracy of the copy. Users should refer to the original$\backslash$npublished version of the material for the full abstract. (Copyright$\backslash$napplies to all Abstracts.)},
archivePrefix = {arXiv},
arxivId = {arXiv:gr-qc/9809069v1},
author = {Bertrand, Marianne and Duflo, Esther and Mullainathan, Sendhil},
doi = {10.1162/003355304772839588},
eprint = {9809069v1},
file = {:Users/hollinal/Documents/mendeley{\_}desktop/Bertrand, Duflo, Mullainathan{\_}2004.pdf:pdf},
isbn = {00335533},
issn = {0033-5533},
journal = {The Quarterly Journal of Economics},
keywords = {ECONOMETRICS,ECONOMICS,MONTE Carlo method,STATISTICS},
month = {feb},
number = {1},
pages = {249--275},
pmid = {18165480},
primaryClass = {arXiv:gr-qc},
title = {{How Much Should We Trust Differences-In-Differences Estimates?}},
url = {https://academic.oup.com/qje/article-lookup/doi/10.1162/003355304772839588},
volume = {119},
year = {2004}
}
@unpublished{Burlig2016,
author = {Burlig, Fiona},
file = {:Users/hollinal/Documents/mendeley{\_}desktop/Burlig{\_}2016.pdf:pdf},
pages = {1--16},
title = {{Class Notes: ARE 212 Section 12 : Power Calculations}},
year = {2016}
}
@unpublished{Burlig2017a,
abstract = {How should researchers design experiments to detect treatment effects with panel data? In this paper, we derive analytical expressions for the variance of panel estimators under non-i.i.d. error structures, which inform power calculations in panel data settings. Using Monte Carlo simulation, we demonstrate that, with correlated errors, traditional methods for experimental design result in experiments that are incorrectly powered with proper inference. Failing to account for serial correlation yields overpowered experiments in short panels and under-powered experiments in long panels. Using both data from a randomized experiment in China and a high-frequency data set of U.S. electricity consumption, we show that these results hold in real-world settings. Our theoretical results enable us to achieve correctly powered experiments in both simulated and real data. This paper provides researchers with the tools to design well-powered experiments in panel data settings.},
author = {Burlig, Fiona and Preonas, Louis and Woerman, Matt},
booktitle = {Ssrn},
doi = {10.2139/ssrn.2892713},
file = {:Users/hollinal/Documents/mendeley{\_}desktop/Burlig, Preonas, Woerman{\_}2017(3).pdf:pdf},
keywords = {B4,C2,C9,O1,Q4,experimental design,panel data,power,sample size},
title = {{Panel Data and Experimental Design}},
year = {2017}
}
@unpublished{Burlig2017b,
abstract = {How should researchers design experiments to detect treatment effects with panel data? In this paper, we derive analytical expressions for the variance of panel estimators under non-i.i.d. error structures, which inform power calculations in panel data settings. Using Monte Carlo simulation, we demonstrate that, with correlated errors, traditional methods for experimental design result in experiments that are incorrectly powered with proper inference. Failing to account for serial correlation yields overpowered experiments in short panels and under-powered experiments in long panels. Using both data from a randomized experiment in China and a high-frequency data set of U.S. electricity consumption, we show that these results hold in real-world settings. Our theoretical results enable us to achieve correctly powered experiments in both simulated and real data. This paper provides researchers with the tools to design well-powered experiments in panel data settings.},
author = {Burlig, Fiona and Preonas, Louis and Woerman, Matt},
booktitle = {Ssrn},
doi = {10.2139/ssrn.2892713},
file = {:Users/hollinal/Documents/mendeley{\_}desktop/Burlig, Preonas, Woerman{\_}2017(4).pdf:pdf},
keywords = {B4,C2,C9,O1,Q4,experimental design,panel data,power,sample size},
pages = {1--73},
title = {{Panel Data and Experimental Design: Appendix}},
year = {2017}
}
@article{Button2013,
abstract = {A study with low statistical power has a reduced chance of detecting a true effect, but it is less well appreciated that low power also reduces the likelihood that a statistically significant result reflects a true effect. Here, we show that the average statistical power of studies in the neurosciences is very low. The consequences of this include overestimates of effect size and low reproducibility of results. There are also ethical dimensions to this problem, as unreliable research is inefficient and wasteful. Improving reproducibility in neuroscience is a key priority and requires attention to well-established but often ignored methodological principles.},
author = {Button, Katherine S. and Ioannidis, John P. A. and Mokrysz, Claire and Nosek, Brian A. and Flint, Jonathan and Robinson, Emma S. J. and Munaf{\`{o}}, Marcus R.},
doi = {10.1038/nrn3475},
file = {:Users/hollinal/Documents/mendeley{\_}desktop/Button et al.{\_}2013.pdf:pdf},
isbn = {1471-0048 (Electronic)$\backslash$n1471-003X (Linking)},
issn = {1471-003X},
journal = {Nature Reviews Neuroscience},
month = {may},
number = {5},
pages = {365--376},
pmid = {23571845},
publisher = {Nature Publishing Group},
title = {{Power failure: why small sample size undermines the reliability of neuroscience}},
url = {http://dx.doi.org/10.1038/nrn3475 http://www.nature.com/articles/nrn3475},
volume = {14},
year = {2013}
}
@techreport{Croke2016,
abstract = {The WHO has recently debated whether to reaffirm its long-standing recommendation of mass drug administration (MDA) in areas with more than 20{\%} prevalence of soil-transmitted helminths (hookworm, whipworm, and roundworm). There is consensus that the relevant deworming drugs are safe and effective, so the key question facing policymakers is whether the expected benefits of MDA exceed the roughly {\$}0.30 per treatment cost. The literature on long run educational and economic impacts of deworming suggests that this is the case. However, a recent meta-analysis by Taylor-Robinson et al. (2015) (hereafter TMSDG), disputes these findings. The authors conclude that while treatment of children known to be infected increases weight by 0.75 kg (95{\%} CI: 0.24, 1.26; p=0.0038), there is substantial evidence that MDA has no impact on weight or other child outcomes. We update the TMSDG analysis by including studies omitted from that analysis and extracting additional data from included studies, such as deriving standard errors from p-values when the standard errors are not reported in the original article. The updated sample includes twice as many trials as analyzed by TMSDG, substantially improving statistical power. We find that the TMSDG analysis is underpowered: it would conclude that MDA has no effect even if the true effect were (1) large enough to be cost-effective relative to other interventions in similar populations, or (2) of a size that is consistent with results from studies of children known to be infected. The hypothesis of a common zero effect of multiple-dose MDA deworming on child weight at longest follow-up is rejected at the 10{\%} level using the TMSDG dataset, and with a p-value {\textless} 0.001 using the updated sample. Applying either of two study classification approaches used in previous Cochrane Reviews (prior to TMSDG) also leads to rejection at the 5{\%} level. In the full sample, including studies in environments where prevalence is low enough that the WHO does not recommend deworming, the average effect on child weight is 0.134 kg (95{\%} CI: 0.031, 0.236, random effects estimation). In environments with greater than 20{\%} prevalence, where the WHO recommends mass treatment, the average effect on child weight is 0.148 kg (95{\%} CI: 0.039, 0.258). The implied average effect of MDA on infected children in the full sample (calculated by dividing estimated impact by worm prevalence for each study and applying a random effects model) is 0.301 kg. At 0.22 kg per U.S. dollar, the estimated average weight gain per dollar expenditure from deworming MDA is more than 35 times that from school feeding programs as estimated in RCTs. Under-powered meta-analyses (such as TMSDG) are common in health research, and this methodological issue will be increasingly important as growing numbers of economists and other social scientists conduct meta-analysis.},
address = {Cambridge, MA},
author = {Croke, Kevin and Hicks, Joan Hamory and Hsu, Eric and Kremer, Michael and Miguel, Edward},
booktitle = {NBER Working Paper Series},
doi = {10.3386/w22382},
file = {:Users/hollinal/Documents/mendeley{\_}desktop/Croke et al.{\_}2016.pdf:pdf},
institution = {National Bureau of Economic Research},
month = {jul},
number = {22382},
title = {{Does Mass Deworming Affect Child Nutrition? Meta-analysis, Cost-Effectiveness, and Statistical Power}},
url = {http://www.nber.org/papers/w22382.pdf},
year = {2016}
}
@unpublished{Dannemiller,
author = {Dannemiller, James L and Serlin, Ronald},
file = {:Users/hollinal/Documents/mendeley{\_}desktop/Dannemiller, Serlin{\_}Unknown.pdf:pdf},
pages = {1--25},
title = {{Some Implications of Factoring Cost into Statistical Power Calculations}}
}
@article{DeLong1992,
abstract = {We develop an estimator that allows us to calculate an upper bound to the fraction of unrejected null hypotheses tested in economics journal articles that are in fact true. Our point estimate is that none of the unrejected nulls in our sample is true. We reject the hypothesis that more than one-third are true. We consider three explanations for this finding: that all null hypotheses are mere approximations, that data-mining biases reported standard errors downward, and that journals tend to publish papers that fail to reject their null hypotheses only when the null hypotheses are likely to be false. While all these explanations are important, the last seems best able to explain our findings.},
author = {{De Long}, J. Bradford and Lang, Kevin},
doi = {10.2307/2138833},
file = {:Users/hollinal/Documents/mendeley{\_}desktop/De Long, Lang{\_}1992.pdf:pdf},
isbn = {00223808},
issn = {0022-3808},
journal = {Journal of Political Economy},
number = {6},
pages = {1257--1272},
title = {{Are all Economic Hypotheses False?}},
volume = {100},
year = {1992}
}
@unpublished{Deke2012,
author = {Deke, John and Dragoset, Lisa},
booktitle = {Mathematica Policy Research, Inc.},
file = {:Users/hollinal/Documents/mendeley{\_}desktop/Deke, Dragoset{\_}2012.pdf:pdf},
keywords = {Education,Empirical Estimates,Randomized Controlled Trials,Regression Discontinuity Designs,Statistical Power},
number = {June},
title = {{Statistical Power for Regression Discontinuity Designs in Education: Empirical Estimates of Design Effects Relative to Randomized Controlled Trials}},
year = {2012}
}
@article{Dong2013,
author = {Dong, Nianbo and Maynard, Rebecca},
doi = {10.1080/19345747.2012.673143},
file = {:Users/hollinal/Documents/mendeley{\_}desktop/Dong, Maynard{\_}2013.pdf:pdf},
issn = {1934-5747},
journal = {Journal of Research on Educational Effectiveness},
month = {jan},
number = {1},
pages = {24--67},
title = {{PowerUp! : A Tool for Calculating Minimum Detectable Effect Sizes and Minimum Required Sample Sizes for Experimental and Quasi-Experimental Design Studies}},
url = {http://www.tandfonline.com/doi/abs/10.1080/19345747.2012.673143},
volume = {6},
year = {2013}
}
@article{Fiedler2012,
abstract = {Abstract$\backslash$r$\backslash$nSeveral influential publications have sensitized the community of behavioral scientists to the dangers of inflated effects$\backslash$r$\backslash$nand false-positive errors leading to the unwarranted publication of nonreplicable findings. This issue has been related to$\backslash$r$\backslash$nprominent cases of data fabrication and survey results pointing to bad practices in empirical science. Although we concur$\backslash$r$\backslash$nwith the motives behind these critical arguments, we note that an isolated debate of false positives may itself be misleading$\backslash$r$\backslash$nand counter-productive. Instead, we argue that, given the current state of affairs in behavioral science, false negatives often$\backslash$r$\backslash$nconstitute a more serious problem. Referring to Wason's (1960) seminal work on inductive reasoning, we show that the failure$\backslash$r$\backslash$nto assertively generate and test alternative hypotheses can lead to dramatic theoretical mistakes, which cannot be corrected$\backslash$r$\backslash$nby any kind of rigor applied to statistical tests of the focal hypotheses. We conclude that a scientific culture rewarding strong$\backslash$r$\backslash$ninference (Platt, 1964) is more likely to see progress than a culture preoccupied with tightening its standards for the mere$\backslash$r$\backslash$npublication of original findings.},
author = {Fiedler, Klaus and Kutzner, Florian and Krueger, Joachim I.},
doi = {10.1177/1745691612462587},
file = {:Users/hollinal/Documents/mendeley{\_}desktop/Fiedler, Kutzner, Krueger{\_}2012.pdf:pdf},
isbn = {1745-6916 1745-6924},
issn = {1745-6916},
journal = {Perspectives on Psychological Science},
keywords = {false negatives,false positives,replicability,strong inference},
month = {nov},
number = {6},
pages = {661--669},
pmid = {26168128},
title = {{The Long Way From $\alpha$-Error Control to Validity Proper}},
url = {http://journals.sagepub.com/doi/10.1177/1745691612462587},
volume = {7},
year = {2012}
}
@article{Foster2001,
abstract = {Statistical power, the ability to detect a specified effect size (ES) (difference among treatments or change over time), if an effect exists, is low in most monitoring studies. A priori power analysis estimates the power of a particular experimental design and answers the following questions. (1) What is the smallest ES that can be detected? (2) How many samples are needed to detect effect sizes of biological or management significance? (3) What is the risk of wrongly accepting a false null hypothesis (Type II error) at a given risk of wrongly rejecting a true null hypothesis (Type I error)? When changes over time are gradual (as during silvicultural conversion of even-aged, second-growth forests to an uneven-aged condition) and resources are limited, power analysis helps allocate sampling effort to maximize the probability of detecting small effect sizes. The power of any particular experimental design can be enhanced by increasing sample size, increasing acceptable Type I error risk, and, in analysis of variance, specifying planned means comparisons. Alternatively, power can be increased by chan-mig experimental design to reduce residual variance and/or increase ES. Use of parametric and one-tailed statistical tests also increases power. The forest monitoring program at Fort Lewis, a military installation, provides an example of the application of power analysis. Published by Elsevier Science B.V.},
author = {Foster, Jeffrey R},
doi = {10.1016/S0378-1127(01)00591-6},
file = {:Users/hollinal/Documents/mendeley{\_}desktop/Foster{\_}2001.pdf:pdf},
isbn = {03781127 (ISSN)},
issn = {03781127},
journal = {Forest Ecology and Management},
keywords = {error,monitoring,sample,statistical power analysis,washington state},
month = {oct},
number = {1-3},
pages = {211--222},
title = {{Statistical power in forest monitoring}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0378112701005916},
volume = {151},
year = {2001}
}
@unpublished{Fowlie2017,
abstract = {A growing number of policies and programs aim to increase investment in energy efficiency, because conventional wisdom suggests that people fail to take-up these investments even though they have positive private returns and generate environmental benefits. Many explanations for this energy efficiency gap have been put forward but there has been surprisingly little field testing of whether the conventional wisdom is correct. This paper reports on the results of an experimental evaluation of the nation's largest residential energy efficiency program – the Weatherization Assistance Program – conducted on a sample of approximately 30,000 households in Michigan. The findings suggest that the upfront investment costs are about twice the actual energy savings. Further, the model-projected savings are more than three times the actual savings. While this might be attributed to the “rebound” effect – when demand for energy end uses increases as a result of greater efficiency – the paper fails to find evidence of significantly higher indoor temperatures at weatherized homes. Even when accounting for the broader societal benefits derived from emissions reductions, the costs still substantially outweigh the benefits; the average rate of return is approximately -7.8{\%} annually.},
author = {Fowlie, Meredith and Greenstone, Michael and Wolfram, Catherine},
file = {:Users/hollinal/Documents/mendeley{\_}desktop/Fowlie, Greenstone, Wolfram{\_}2017.pdf:pdf},
pages = {1--23},
title = {{Do Energy Efficiency Investments Deliver? Evidence from the Weatherization Assistance Program: Online Appendix}},
year = {2017}
}
@article{Fowlie2018,
abstract = {A growing number of policies and programs aim to increase investment in energy efficiency, because conventional wisdom suggests that people fail to take-up these investments even though they have positive private returns and generate environmental benefits. Many explanations for this energy efficiency gap have been put forward but there has been surprisingly little field testing of whether the conventional wisdom is correct. This paper reports on the results of an experimental evaluation of the nation's largest residential energy efficiency program – the Weatherization Assistance Program – conducted on a sample of approximately 30,000 households in Michigan. The findings suggest that the upfront investment costs are about twice the actual energy savings. Further, the model-projected savings are more than three times the actual savings. While this might be attributed to the “rebound” effect – when demand for energy end uses increases as a result of greater efficiency – the paper fails to find evidence of significantly higher indoor temperatures at weatherized homes. Even when accounting for the broader societal benefits derived from emissions reductions, the costs still substantially outweigh the benefits; the average rate of return is approximately -7.8{\%} annually.},
author = {Fowlie, Meredith and Greenstone, Michael and Wolfram, Catherine},
doi = {10.1093/qje/qjy005},
file = {:Users/hollinal/Documents/mendeley{\_}desktop/Fowlie, Greenstone, Wolfram{\_}2018.pdf:pdf},
isbn = {08953309},
issn = {0033-5533},
journal = {The Quarterly Journal of Economics},
keywords = {efficiency investments,energy},
month = {aug},
number = {3},
pages = {1597--1644},
pmid = {71755052},
title = {{Do Energy Efficiency Investments Deliver? Evidence from the Weatherization Assistance Program*}},
url = {http://www.ssrn.com/abstract=2621817 https://academic.oup.com/qje/article/133/3/1597/4828342},
volume = {133},
year = {2018}
}
@article{Gallet2017,
abstract = {While numerous studies assess the impact of healthcare spending on health outcomes, typically reporting multiple estimates of the elasticity of health outcomes (most often measured by a mortality rate or life expectancy) with respect to healthcare spending, the extent to which study attributes influence these elasticity estimates is unclear. Accordingly, we utilize a meta-data set (consisting of 65 studies completed over the 1969–2014 period) to examine these elasticity estimates using meta-regression analysis (MRA). Correcting for a number of issues, including publication selection bias, healthcare spending is found to have the greatest impact on the mortality rate compared to life expectancy. Indeed, conditional on several features of the literature, the spending elasticity for mortality is near −0.13, whereas it is near to +0.04 for life expectancy. MRA results reveal that the spending elasticity for the mortality rate is particularly sensitive to data aggregation, the specification of the health production function, and the nature of healthcare spending. The spending elasticity for life expectancy is particularly sensitive to the age at which life expectancy is measured, as well as the decision to control for the endogeneity of spending in the health production function. With such results in hand, we have a better understanding of how modeling choices influence results reported in this literature.},
author = {Gallet, Craig A. and Doucouliagos, Hristos},
doi = {10.1016/j.socscimed.2017.02.024},
file = {:Users/hollinal/Documents/mendeley{\_}desktop/Gallet, Doucouliagos{\_}2017.pdf:pdf},
issn = {02779536},
journal = {Social Science {\&} Medicine},
keywords = {Healthcare spending,Life expectancy,Meta-regression,Mortality,Publication bias},
month = {apr},
pages = {9--17},
pmid = {28237460},
publisher = {Elsevier Ltd},
title = {{The impact of healthcare spending on health outcomes: A meta-regression analysis}},
url = {http://dx.doi.org/10.1016/j.socscimed.2017.02.024 http://linkinghub.elsevier.com/retrieve/pii/S0277953617301132},
volume = {179},
year = {2017}
}
@article{Gelman2018a,
author = {Gelman, Andrew},
doi = {10.1097/SLA.0000000000002908},
file = {:Users/hollinal/Documents/mendeley{\_}desktop/Gelman{\_}2018(2).pdf:pdf},
isbn = {0000000000},
issn = {0003-4932},
journal = {Annals of Surgery},
month = {jul},
number = {Xx},
pages = {1},
title = {{Don't Calculate Post-hoc Power Using Observed Estimate of Effect Size}},
url = {http://insights.ovid.com/crossref?an=00000658-900000000-95527},
volume = {XX},
year = {2018}
}
@misc{Gelman2005,
author = {Gelman, Andrew},
file = {:Users/hollinal/Documents/mendeley{\_}desktop/Gelman{\_}2005.pdf:pdf},
title = {{Power calculations}},
year = {2005}
}
@article{Gelman2018,
abstract = {A standard mode of inference in social and behavioral science is to establish stylized facts using statistical significance in quantitative studies. However, in a world in which measurements are noisy and effects are small, this will not work: selection on statistical significance leads to effect sizes which are overestimated and often in the wrong direction. After a brief discussion of two examples, one in economics and one in social psychology, we consider the procedural solution of open postpublication review, the design solution of devoting more effort to accurate measurements and within-person comparisons, and the statistical analysis solution of multilevel modeling and reporting all results rather than selection on significance. We argue that the current replication crisis in science arises in part from the ill effects of null hypothesis significance testing being used to study small effects with noisy data. In such settings, apparent success comes easy but truly replicable results require a more se...},
author = {Gelman, Andrew},
doi = {10.1177/0146167217729162},
file = {:Users/hollinal/Documents/mendeley{\_}desktop/Gelman{\_}2018.pdf:pdf},
issn = {0146-1672},
journal = {Personality and Social Psychology Bulletin},
keywords = {economics,null hypothesis significance testing,replication crisis,statistics},
month = {jan},
number = {1},
pages = {16--23},
pmid = {28914154},
title = {{The Failure of Null Hypothesis Significance Testing When Studying Incremental Changes, and What to Do About It}},
url = {http://journals.sagepub.com/doi/10.1177/0146167217729162},
volume = {44},
year = {2018}
}
@misc{Gelman2017a,
author = {Gelman, Andrew},
file = {:Users/hollinal/Documents/mendeley{\_}desktop/Gelman{\_}2017(2).pdf:pdf},
pages = {1--13},
title = {{The 80{\%} power lie}},
year = {2017}
}
@misc{Gelman2017,
author = {Gelman, Andrew},
file = {:Users/hollinal/Documents/mendeley{\_}desktop/Gelman{\_}2017.pdf:pdf},
pages = {1--21},
title = {{Yes, it makes sense to do design analysis (“power calculations”) after the data have been collected}},
year = {2017}
}
@article{Gelman2008,
author = {Gelman, Andrew},
file = {:Users/hollinal/Documents/mendeley{\_}desktop/Gelman{\_}2008.pdf:pdf},
pages = {2008},
title = {{What is the point, if any, of retrospective power calculations?}},
year = {2008}
}
@article{Gelman2014,
abstract = {Statistical power analysis provides the conventional approach to assess error rates when designing a research study. However, power analysis is flawed in that a narrow emphasis on statistical significance is placed as the primary focus of study design. In noisy, small-sample settings, statistically significant results can often be misleading. To help researchers address this problem in the context of their own studies, we recommend design calculations in which (a) the probability of an estimate being in the wrong direction (Type S [sign] error) and (b) the factor by which the magnitude of an effect might be overestimated (Type M [magnitude] error or exaggeration ratio) are estimated. We illustrate with examples from recent published research and discuss the largest challenge in a design calculation: coming up with reasonable estimates of plausible effect sizes based on external information.},
author = {Gelman, Andrew and Carlin, John},
doi = {10.1177/1745691614551642},
file = {:Users/hollinal/Documents/mendeley{\_}desktop/Gelman, Carlin{\_}2014(2).pdf:pdf},
isbn = {1745-6924 (Electronic) 1745-6916 (Linking)},
issn = {1745-6916},
journal = {Perspectives on Psychological Science},
keywords = {Type M error,Type S error,design calculation,exaggeration ratio,power analysis,replication crisis,statistical significance},
month = {nov},
number = {6},
pages = {641--651},
pmid = {26186114},
title = {{Beyond Power Calculations: Assessing Type S (Sign) and Type M (Magnitude) Errors}},
url = {http://journals.sagepub.com/doi/10.1177/1745691614551642},
volume = {9},
year = {2014}
}
@incollection{Gelman2006,
abstract = {Multilevel modeling is typically motivated by features in existing data or the object of study—for example, voters classified by demography and geography, students in schools, multiple measurements on individuals, and so on. Consider all the examples in Part 2 of this book. In some settings, however, multilevel data structures arise by choice from the data collection process. We briefly discuss some of these options here. Unit sampling or cluster sampling In a sample survey, data are collected on a set of units in order to learn about a larger population. In unit sampling, the units are selected directly from the population. In cluster sampling, the population is divided into clusters: first a sample of clusters is selected, then data are collected from each of the sampled clusters. In one-stage cluster sampling, complete information is collected within each sam-pled cluster. For example, a set of classrooms is selected at random from a larger population, and then all the students within each sampled classroom are inter-viewed. In two-stage cluster sampling, a sample is performed within each sampled cluster. For example, a set of classrooms is selected, and then a random sample of ten students within each classroom is selected and interviewed. More complicated sampling designs are possible along these lines, including adaptive designs, strati-fied cluster sampling, sampling with probability proportional to size, and various combinations and elaborations of these. Observational studies or experiments with unit-level or group-level treatments},
author = {Gelman, Andrew and Hill, Jennifer},
booktitle = {Data Analysis Using Regression and Multilevel/Hierarchical Models},
doi = {10.1097/EDE.0b013e31822e18e5},
file = {:Users/hollinal/Documents/mendeley{\_}desktop/Gelman, Hill{\_}2006.pdf:pdf},
isbn = {978-0-521-68689-1},
issn = {1531-5487},
pages = {437--456},
pmid = {21968778},
title = {{Sample size and power calculations}},
year = {2006}
}
@article{Gelman2008a,
abstract = {A series of papers in the Journal of Theoretical Biology has found evidence that beautiful parents have more daughters, violent men have more sons, and other sex-ratio patterns (Kanazawa, 2005, 2006, 2007).  These papers have been shown to have statistical errors, but the question remains how to interpret ﬁndings that are intriguing, potentially important, but not statistically signiﬁcant.  From a classical statistical perspective, these studies have insuffcient power to detect the magnitudes of effects (on the order of 1 percentage point) that could be expected based on earlier studies of sex ratios. The anticipated small effects can also be handled using a Bayesian prior distribution.  These concerns are relevant to other studies of small effects and also to the reporting of such studies.},
author = {Gelman, Andrew and Weakliem, D},
file = {:Users/hollinal/Documents/mendeley{\_}desktop/Gelman, Weakliem{\_}2008(2).pdf:pdf},
keywords = {bayesian inference,bution,error,evolutionary psychology,magnitude,power analysis,prior distri-,sex ratio,sociobiology,trivers-willard hypothesis,type m},
pages = {1--16},
title = {{Of beauty, sex, and power: Statistical challenges in estimating small effects}},
year = {2008}
}
@unpublished{Gelman2008,
abstract = {A series of papers in the Journal of Theoretical Biology has found evidence that beautiful parents have more daughters, violent men have more sons, and other sex-ratio patterns (Kanazawa, 2005, 2006, 2007). These papers have been shown to have statistical errors, but the question remains how to interpret ﬁndings that are intriguing, potentially important, but not statistically signiﬁcant. From a classical statistical perspective, these studies have insuffcient power to detect the magnitudes of effects (on the order of 1 percentage point) that could be expected based on earlier studies of sex ratios. The anticipated small effects can also be handled using a Bayesian prior distribution. These concerns are relevant to other studies of small effects and also to the reporting of such studies.},
author = {Gelman, Andrew and Weakliem, D},
file = {:Users/hollinal/Documents/mendeley{\_}desktop/Gelman, Weakliem{\_}2008.pdf:pdf},
keywords = {bayesian inference,bution,error,evolutionary psychology,magnitude,power analysis,prior distri-,sex ratio,sociobiology,trivers-willard hypothesis,type m},
pages = {1--16},
title = {{Of beauty, sex, and power: Statistical challenges in estimating small effects}},
year = {2008}
}
@article{Gelman2009,
author = {Gelman, Andrew and Weakliem, David},
file = {:Users/hollinal/Documents/mendeley{\_}desktop/Gelman, Weakliem{\_}2009.pdf:pdf},
journal = {The American Scientist},
number = {July-August},
pages = {310--316},
title = {{Of Beauty, Sex, and Power}},
volume = {97},
year = {2009}
}
@book{Gerin2017,
address = {Los Angeles, CA},
author = {Gerin, William and Kapelewski, Christine and Page, Niki L.},
edition = {3rd},
isbn = {978-1506357737},
pages = {232},
publisher = {SAGE Publications, Inc},
title = {{Writing the NIH Grant Proposal: A Step-by-Step Guide}},
year = {2017}
}
@article{Hannon1993,
author = {Hannon, Susan J. and Martin, Kathy and Thomas, Len and Schieck, Jim},
file = {:Users/hollinal/Documents/mendeley{\_}desktop/Hannon et al.{\_}1993.pdf:pdf},
journal = {Journal of Field Ornithology},
number = {4},
pages = {575--586},
title = {{Investigator Disturbance and Clutch Predation in Willow Ptarmigan : Methods for Evaluating Impact}},
volume = {64},
year = {1993}
}
@article{Hoenig2001,
abstract = {It is well known that statistical power calculations can be valuable in planning an experiment. There is also a large lit- erature advocating that power calculations be made when- ever one performs a statistical test of a hypothesis and one obtains a statistically nonsignificant result. Advocates of such post-experiment power calculations claim the calcu- lations should be used to aid in the interpretation of the experimental results. This approach, which appears in vari- ous forms, is fundamentally flawed. We document that the problem is extensive and present arguments to demonstrate the flaw in the logic.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Hoenig, John M. and Heisey, Dennis M.},
doi = {10.1198/000313001300339897},
eprint = {arXiv:1011.1669v3},
file = {:Users/hollinal/Documents/mendeley{\_}desktop/Hoenig, Heisey{\_}2001.pdf:pdf},
isbn = {0003-1305},
issn = {0003-1305},
journal = {The American Statistician},
keywords = {Bioequivalence testing,Burden of proof,Observed power,Retrospective power analysis,Statistical power,Type II error},
month = {feb},
number = {1},
pages = {19--24},
pmid = {11310512},
title = {{The Abuse of Power: The Pervasive Fallacy of Power Calculations for Data Analysis}},
url = {http://www.tandfonline.com/doi/abs/10.1198/000313001300339897},
volume = {55},
year = {2001}
}
@unpublished{Hsiang2009,
abstract = {Contract farming has expanded in Uganda due to the promotional efforts of various actors: private, public, and/or international aid agencies. While motives for promoting contract farming may vary by actor, it is argued in this study that contract farming is crucial in the commercialization of smallholder agriculture and hence, poverty reduction in Uganda. However, smallholder farmers in Uganda have reportedly experienced some contractual problems when dealing with large agribusiness firms, resulting in them giving up contract farming. Similarly, agribusinesses have also reportedly encountered some contractual problems when dealing with some smallholder farmers that could have led to the exclusion of the latter from contract farming. Therefore, the main objective of this study was to examine the role of contract farming in the commercialization of smallholder agriculture in Uganda by using sunflower, sorghum, and rice contract schemes as case studies. Specifically, the study sought to characterize the sorghum, sunflower, and rice contract schemes as well as identify benefits and problems associated with them. Primary data were collected by a combined use of survey and informal interview methods. A survey of both contracted and non contracted farmers was conducted in Soroti District (Sorghum), Apac District (Sunflower), and Bugiri District (Rice). Informal interviews were held with agribusiness firms (Nile Breweries Limited, Mukwano Industries, and Tilda (U) Limited), their agents, and support organizations. Data were then analyzed using descriptive statistics and non parametric tests (Chi- square and F-tests). While most of the findings from this study are general in nature, some of them are idiosyncratic to the case studies investigated. It was generally found contract farming contributed a great deal to the commercialization of smallholder agriculture in Uganda, especially in the sorghum (Epuripur) and sunflower sub-sectors. While agribusinesses obtained assured supply of raw materials for their processing needs, smallholder farmers on the other hand had access to critical inputs such as improved seeds and extension services, in addition to access to a guaranteed market for their produce. However, there were still some challenges in the organization and operation of the contract farming schemes. Thus, both agribusinesses and policy makers have separate roles to play in making sure contract farming is properly nurtured for the benefit of smallholder farmers in Uganda.},
author = {Hsiang, Solomon M and Burke, Marshall and Miguel, Edward and Meng, Kyle and Cane, Mark},
file = {:Users/hollinal/Documents/mendeley{\_}desktop/Hsiang et al.{\_}2009.pdf:pdf},
keywords = {Commercialization,Contract Farming,Rice,Smallholder Farmers,Sorghum,Sunflower,Uganda},
pages = {33},
title = {{Analysis of statistical power reconciles drought-conflict results in Africa}},
year = {2009}
}
@article{IntHout2016,
author = {IntHout, Joanna and Ioannidis, John PA and Borm, George F},
doi = {10.1177/0962280212461098},
issn = {0962-2802},
journal = {Statistical Methods in Medical Research},
month = {apr},
number = {2},
pages = {538--552},
title = {{Obtaining evidence by a single well-powered trial or several modestly powered trials}},
url = {http://journals.sagepub.com/doi/10.1177/0962280212461098},
volume = {25},
year = {2016}
}
@article{Ioannidis2005a,
abstract = {There is increasing concern that most current published research findings are false. The probability that a research claim is true may depend on study power and bias, the number of other studies on the same question, and, importantly, the ratio of true to no relationships among the relationships probed in each scientific field. In this framework, a research finding is less likely to be true when the studies conducted in a field are smaller; when effect sizes are smaller; when there is a greater number and lesser preselection of tested relationships; where there is greater flexibility in designs, definitions, outcomes, and analytical modes; when there is greater financial and other interest and prejudice; and when more teams are involved in a scientific field in chase of statistical significance. Simulations show that for most study designs and settings, it is more likely for a research claim to be false than true. Moreover, for many current scientific fields, claimed research findings may often be simply accurate measures of the prevailing bias. In this essay, I discuss the implications of these problems for the conduct and interpretation of research.},
archivePrefix = {arXiv},
arxivId = {gr-qc/0208024},
author = {Ioannidis, John P A},
doi = {10.1371/journal.pmed.0020124},
eprint = {0208024},
file = {:Users/hollinal/Documents/mendeley{\_}desktop/Ioannidis{\_}2005.pdf:pdf},
isbn = {3540239081},
issn = {1549-1676},
journal = {PLoS Medicine},
month = {aug},
number = {8},
pages = {e124},
pmid = {16060722},
primaryClass = {gr-qc},
title = {{Why Most Published Research Findings Are False}},
url = {http://dx.plos.org/10.1371/journal.pmed.0020124},
volume = {2},
year = {2005}
}
@article{Ioannidis2017,
abstract = {We investigate two critical dimensions of the credibility of empirical economics research: statistical power and bias. We survey 159 empirical economics literatures that draw upon 64,076 estimates of economic parameters reported in more than 6,700 empirical studies. Half of the research areas have nearly 90{\%} of their results under{\&}{\#}8208;powered. The median statistical power is 18{\%}, or less. A simple weighted average of those reported results that are adequately powered (power{\&}{\#}160;{\&}{\#}8805;{\&}{\#}160;80{\%}) reveals that nearly 80{\%} of the reported effects in these empirical economics literatures are exaggerated; typically, by a factor of two and with one{\&}{\#}8208;third inflated by a factor of four or more.},
author = {Ioannidis, John P. A. and Stanley, T. D. and Doucouliagos, Hristos},
doi = {10.1111/ecoj.12461},
file = {:Users/hollinal/Documents/mendeley{\_}desktop/Ioannidis, Stanley, Doucouliagos{\_}2017.pdf:pdf},
isbn = {0013-0133},
issn = {00130133},
journal = {The Economic Journal},
keywords = {bias,credibility,empirical economics,publication bias,statistical power},
month = {oct},
number = {605},
pages = {F236--F265},
title = {{The Power of Bias in Economics Research}},
url = {http://doi.wiley.com/10.1111/ecoj.12461},
volume = {127},
year = {2017}
}
@article{Ioannidis2013,
abstract = {Objective: To model how to select the optimal pair of type I and type II errors that maximize study value when there are constrains on the available study sample size. Study Design and Setting: Correct inferences [true positives (TPs) and true negatives (TNs)] increase and wrong inferences (false positives and false negatives) decrease the value of a study. We model the composite value of a study based on these four inferences, their relative importance, and relative frequency using multiplicative and additive models. Numerical examples are presented for randomized trials, epidemiologic studies, and agnostic omics investigations with massive testing and variable sample size constraints. Results: The optimal choice of type I and type II errors varies a lot according to the available sample size and the plausible effect sizes in each field. We show how equations can be streamlined for special applications: when the value of all four inferences is considered equal, when the identification of TNs carries no value, and when a study carries no value unless at least one TP is discovered. Conclusion: The proposed optimization equations can be used to guide the selection of the optimal type I and type II errors of future studies in which sample size is constrained. {\textcopyright} 2013 Elsevier Inc. All rights reserved.},
author = {Ioannidis, John P.A. and Hozo, Iztok and Djulbegovic, Benjamin},
doi = {10.1016/j.jclinepi.2013.03.002},
file = {:Users/hollinal/Documents/mendeley{\_}desktop/Ioannidis, Hozo, Djulbegovic{\_}2013.pdf:pdf},
isbn = {1878-5921 (Electronic)$\backslash$n0895-4356 (Linking)},
issn = {08954356},
journal = {Journal of Clinical Epidemiology},
keywords = {False negative,False positive,Optimization,Power calculations,Type I error,Type II error},
month = {aug},
number = {8},
pages = {903--910.e2},
pmid = {23664493},
publisher = {Elsevier Inc},
title = {{Optimal type I and type II error pairs when the available sample size is fixed}},
url = {http://dx.doi.org/10.1016/j.jclinepi.2013.03.002 http://linkinghub.elsevier.com/retrieve/pii/S0895435613000887},
volume = {66},
year = {2013}
}
@article{Leamer1983,
author = {Leamer, By Edward E},
file = {:Users/hollinal/Documents/mendeley{\_}desktop/Leamer{\_}1983.pdf:pdf},
journal = {The American Economic Review},
number = {1},
pages = {31--43},
title = {{Let's Take the Con Out of Econometrics}},
volume = {73},
year = {1983}
}
@article{Lenth2001,
abstract = {Sample-size determination is often an important step in planning a statistical studyand it is usually a difficult one. Among the important hurdles to be surpassed, one must obtain an estimate of one or more error variances, and specify an effect size of importance. There is the temptation to take some shortcuts. This paper offers some suggestions for successful and meaningful sample-size determination. Also discussed is the possibility that sample size may not be the main issue, that the real goal is to design a high-quality study. Finally, criticism is made of some ill-advised shortcuts relating to power and sample size.},
author = {Lenth, Russell V.},
doi = {10.1198/000313001317098149},
file = {:Users/hollinal/Documents/mendeley{\_}desktop/Lenth{\_}2001.pdf:pdf},
isbn = {0003130515372},
issn = {0003-1305},
journal = {The American Statistician},
keywords = {Cohen's effect measures,Equivalence testing,Observed power,Power,Retrospective power,Study design},
month = {aug},
number = {3},
pages = {187--193},
pmid = {20598730},
title = {{Some Practical Guidelines for Effective Sample Size Determination}},
url = {http://www.tandfonline.com/doi/abs/10.1198/000313001317098149},
volume = {55},
year = {2001}
}
@article{Maniadis2017,
abstract = {The sciences are in an era of an alleged {\&}{\#}8216;credibility crisis{\&}{\#}8217;. In this study, we discuss the reproducibility of empirical results, focusing on economics research. By combining theory and empirical evidence, we discuss the import of replication studies and whether they improve our confidence in novel findings. The theory sheds light on the importance of replications, even when replications are subject to bias. We then present a pilot meta{\&}{\#}8208;study of replication in experimental economics, a subfield serving as a positive benchmark for investigating the credibility of economics. Our meta{\&}{\#}8208;study highlights certain difficulties when applying meta{\&}{\#}8208;research to systematise the economics literature.},
author = {Maniadis, Zacharias and Tufano, Fabio and List, John A.},
doi = {10.1111/ecoj.12527},
file = {:Users/hollinal/Documents/mendeley{\_}desktop/Maniadis, Tufano, List{\_}2017.pdf:pdf},
issn = {00130133},
journal = {The Economic Journal},
month = {oct},
number = {605},
pages = {F209--F235},
title = {{To Replicate or Not To Replicate? Exploring Reproducibility in Economics through the Lens of a Model and a Pilot Study}},
url = {http://doi.wiley.com/10.1111/ecoj.12527},
volume = {127},
year = {2017}
}
@article{Maxwell2004,
abstract = {Underpowered studies persist in the psychological literature. This article examines reasons for their persistence and the effects on efforts to create a cumulative science. The "curse of multiplicities" plays a central role in the presentation. Most psychologists realize that testing multiple hypotheses in a single study affects the Type I error rate, but corresponding implications for power have largely been ignored. The presence of multiple hypothesis tests leads to 3 different conceptualizations of power. Implications of these 3 conceptualizations are discussed from the perspective of the individual researcher and from the perspective of developing a coherent literature. Supplementing significance tests with effect size measures and confidence intervals is shown to address some but not necessarily all problems associated with multiple testing.},
author = {Maxwell, Scott E.},
doi = {10.1037/1082-989X.9.2.147},
file = {:Users/hollinal/Documents/mendeley{\_}desktop/Maxwell{\_}2004.pdf:pdf},
isbn = {1939-1463 (Electronic); 1082-989X (Print)},
issn = {1939-1463},
journal = {Psychological Methods},
number = {2},
pages = {147--163},
pmid = {15137886},
title = {{The Persistence of Underpowered Studies in Psychological Research: Causes, Consequences, and Remedies.}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/1082-989X.9.2.147},
volume = {9},
year = {2004}
}
@article{Mccloskey1996,
author = {McCloskey, Deirdre N and Ziliak, Stephen T},
file = {:Users/hollinal/Documents/mendeley{\_}desktop/McCloskey, Ziliak{\_}1996.pdf:pdf},
journal = {Journal of Economic Literature},
number = {1},
pages = {97--114},
title = {{The Standard Error of Regressions}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1053535704000836},
volume = {34},
year = {1996}
}
@article{Mccloskey1985,
author = {McCloskey, Donald},
doi = {10.2307/1805596},
file = {:Users/hollinal/Documents/mendeley{\_}desktop/McCloskey{\_}1985.pdf:pdf},
journal = {American Economic Review: Papers and Proceedings},
number = {2},
pages = {201--205},
title = {{The Loss Function Has Been Mislaid : The Rhetoric of Significance Tests}},
volume = {75},
year = {1985}
}
@article{Munafo2017,
abstract = {Improving the reliability and efficiency of scientific research will increase the credibility of the published scientific literature and accelerate discovery. Here we argue for the adoption of measures to optimize key elements of the scientific process: methods, reporting and dissemination, reproducibility, evaluation and incentives. There is some evidence from both simulations and empirical studies supporting the likely effectiveness of these measures, but their broad adoption by researchers, institutions, funders and journals will require iterative evaluation and improvement. We discuss the goals of these measures, and how they can be implemented, in the hope that this will facilitate action toward improving the transparency, reproducibility and efficiency of scientific research.},
author = {Munaf{\`{o}}, Marcus R. and Nosek, Brian A. and Bishop, Dorothy V.M. and Button, Katherine S. and Chambers, Christopher D. and {Percie Du Sert}, Nathalie and Simonsohn, Uri and Wagenmakers, Eric Jan and Ware, Jennifer J. and Ioannidis, John P.A.},
doi = {10.1038/s41562-016-0021},
file = {:Users/hollinal/Documents/mendeley{\_}desktop/Munaf{\`{o}} et al.{\_}2017.pdf:pdf},
isbn = {4156201600},
issn = {23973374},
journal = {Nature Human Behaviour},
number = {1},
pages = {1--9},
pmid = {25516371},
publisher = {Macmillan Publishers Limited},
title = {{A manifesto for reproducible science}},
url = {http://dx.doi.org/10.1038/s41562-016-0021},
volume = {1},
year = {2017}
}
@misc{Review2016,
abstract = {The goal of this initiative is to enhance reproducibility of research through rigor and transparency. NIH recently updated application instructions and review language for research grant (NOT-OD-16-011) and mentored career development award (NOT-OD-16-012) applications submitted for due dates of January 25, 2016 and beyond. Implementation of rigor and transparency for individual fellowship, institutional career development, and institutional training grant applications will be announced in advance, on a different timeline that allows for training in rigor and transparency to be developed (NOT-OD-16-034). The four areas of the current rigor and transparency initiative are explained below. • Scientific Premise refers to the quality and strength of the prior research used as the basis for the proposed research question or project; this is distinct from the hypothesis or justification. o The applicant should discuss the strengths and weaknesses of the prior research used to support the application and describe how the proposed research will address weaknesses or gaps identified by the applicant. For example, a discussion of scientific premise might include attention to the rigor of previous experimental designs, either conducted by the applicant or reported in the literature. o Reviewers will evaluate scientific premise as part of the Significance criterion for research grant applications or the Research Plan criterion for mentored career development award applications.  Consider whether the applicant has discussed the strengths and weaknesses of the foundational data.  A weak scientific premise, or the failure to address scientific premise adequately, may affect criterion and overall impact scores.  The page limit is not an acceptable excuse for an applicant to not address scientific premise. • Scientific Rigor is the strict application of the scientific method to ensure robust and unbiased experimental design, methodology, analysis, interpretation and reporting of results. Whereas scientific premise pertains to supporting data, scientific rigor pertains to the proposed research.},
author = {NIH},
booktitle = {Reviewer Guidance on Rigor and Transparency: Research Project Grant and Mentored Career Development Applications},
file = {:Users/hollinal/Documents/mendeley{\_}desktop/NIH{\_}2016.pdf:pdf},
keywords = {General Guidance Document},
pages = {1--4},
title = {{Reviewer Guidance on Rigor and Transparency : Research Project Grant and Mentored Career Development Applications}},
url = {https://grants.nih.gov/grants/peer/guidelines{\_}general/Reviewer{\_}Guidance{\_}on{\_}Rigor{\_}and{\_}Transparency.pdf},
year = {2016}
}
@article{Schochet2011,
abstract = {For RCTs of education interventions, it is often of interest to estimate associations between student and mediating teacher practice outcomes, to examine the extent to which the study's conceptual model is supported by the data, and to identify specific mediators that are most associated with student learning. This article develops statistical power formulas for such exploratory analyses under clustered school-based RCTs using ordinary least squares (OLS) and instrumental variable (IV) estimators and uses these formulas to conduct a simulated power analysis. The power analysis finds that for currently available mediators, the OLS approach will yield precise estimates of associations between teacher practice measures and student test score gains only if the sample contains about 150 to 200 study schools. The IV approach, which can adjust for potential omitted variable and simultaneity biases, has very little statistical power for mediator analyses. For typical RCT evaluations, these results may have design implications for the scope of the data collection effort for obtaining costly teacher practice mediators.},
author = {Schochet, Peter Z.},
doi = {10.3102/1076998610375840},
file = {:Users/hollinal/Documents/mendeley{\_}desktop/Schochet{\_}2011.pdf:pdf},
isbn = {1076-9986},
issn = {1076-9986},
journal = {Journal of Educational and Behavioral Statistics},
keywords = {Randomized control trials,clustered designs,education interventions,instrumental variables,mediational analyses,statistical power},
month = {aug},
number = {4},
pages = {441--471},
title = {{Do Typical RCTs of Education Interventions Have Sufficient Statistical Power for Linking Impacts on Teacher Practice and Student Achievement Outcomes?}},
url = {http://journals.sagepub.com/doi/10.3102/1076998610375840},
volume = {36},
year = {2011}
}
@article{Schochet2008,
abstract = {This article examines theoretical and empirical issues related to the statistical power of impact estimates for experimental evaluations of education programs. The author considers designs where random assignment is conducted at the school, classroom, or student level, and employs a unified analytic framework using statistical methods from the literature. Focusing on standardized test scores of elementary school students, this article discusses appropriate precision standards and, for each design, the required number of schools to achieve those standards using empirical values of intraclass correlations, regression R2 values, and other parameters. Clustering effects vary by design but are typically large. Thus, large school samples are required for education trials, and many evaluations will only have sufficient power to detect precise impacts for relatively large subgroups of sites.},
author = {Schochet, Peter Z.},
doi = {10.3102/1076998607302714},
file = {:Users/hollinal/Documents/mendeley{\_}desktop/Schochet{\_}2008.pdf:pdf},
isbn = {1076998607},
issn = {1076-9986},
journal = {Journal of Educational and Behavioral Statistics},
month = {mar},
number = {1},
pages = {62--87},
pmid = {216385513},
title = {{Statistical Power for Random Assignment Evaluations of Education Programs}},
url = {http://jeb.sagepub.com/cgi/doi/10.3102/1076998607302714 http://journals.sagepub.com/doi/10.3102/1076998607302714},
volume = {33},
year = {2008}
}
@article{Senn2002,
author = {Senn, S. J},
doi = {10.1136/bmj.325.7375.1304},
file = {:Users/hollinal/Documents/mendeley{\_}desktop/Senn{\_}2002.pdf:pdf},
issn = {09598138},
journal = {BMJ},
month = {nov},
number = {7375},
pages = {1304--1304},
title = {{Power is indeed irrelevant in interpreting completed studies}},
url = {http://www.bmj.com/cgi/doi/10.1136/bmj.325.7375.1299 http://www.bmj.com/cgi/doi/10.1136/bmj.325.7375.1304},
volume = {325},
year = {2002}
}
@incollection{Senn2008,
author = {Senn, Stephen},
booktitle = {Statistical Issues in Drug Development},
chapter = {13},
edition = {2nd},
file = {:Users/hollinal/Documents/mendeley{\_}desktop/Senn{\_}2008.pdf:pdf},
isbn = {978-0470018774},
pages = {195--212},
title = {{Determining the Sample Size}},
year = {2008}
}
@incollection{Steidl2001,
author = {Steidl, Robert J. and Thomas, Len},
booktitle = {Design and Analysis of Ecological Experiments},
chapter = {2},
file = {:Users/hollinal/Documents/mendeley{\_}desktop/Steidl, Thomas{\_}2001.pdf:pdf},
pages = {14--36},
title = {{Power Analysis and Experimental Design}},
year = {2001}
}
@article{Stigler1977,
author = {Stigler, Stephen},
file = {:Users/hollinal/Documents/mendeley{\_}desktop/Stigler{\_}1977.pdf:pdf},
journal = {Annals of Statistics},
number = {6},
pages = {1055--1098},
title = {{Do robust estimators work with real data?}},
volume = {5},
year = {1977}
}
@article{Taylor-Robinson2015,
abstract = {BACKGROUND The World Health Organization (WHO) recommends treating all school children at regular intervals with deworming drugs in areas where helminth infection is common. As the intervention is often claimed to have important health, nutrition, and societal effects beyond the removal of worms, we critically evaluated the evidence on benefits. OBJECTIVES To summarize the effects of giving deworming drugs to children to treat soil-transmitted helminths on weight, haemoglobin, and cognition; and the evidence of impact on physical well-being, school attendance, school performance, and mortality. SEARCH METHODS We searched the Cochrane Infectious Diseases Group Specialized Register (14 April 2015); Cochrane Central Register of Controlled Trials (CENTRAL), published in the Cochrane Library (2015, Issue 4); MEDLINE (2000 to 14 April 2015); EMBASE (2000 to 14 April 2015); LILACS (2000 to 14 April 2015); the metaRegister of Controlled Trials (mRCT); and reference lists, and registers of ongoing and completed trials up to 14 April 2015. SELECTION CRITERIA We included randomized controlled trials (RCTs) and quasi-RCTs comparing deworming drugs for soil-transmitted helminths with placebo or no treatment in children aged 16 years or less, reporting on weight, haemoglobin, and formal tests of intellectual development. We also sought data on school attendance, school performance, and mortality. We included trials that combined health education with deworming programmes. DATA COLLECTION AND ANALYSIS At least two review authors independently assessed the trials, evaluated risk of bias, and extracted data. We analysed continuous data using the mean difference (MD) with 95{\%} confidence intervals (CIs). Where data were missing, we contacted trial authors. We used outcomes at time of longest follow-up. The evidence quality was assessed using GRADE. This edition of the Cochrane Review adds the DEVTA trial from India, and draws on an independent analytical replication of a trial from Kenya. MAIN RESULTS We identified 45 trials, including nine cluster-RCTs, that met the inclusion criteria. One trial evaluating mortality included over one million children, and the remaining 44 trials included a total of 67,672 participants. Eight trials were in children known to be infected, and 37 trials were carried out in endemic areas, including areas of high (15 trials), moderate (12 trials), and low prevalence (10 trials). Treating children known to be infectedTreating children known to be infected with a single dose of deworming drugs (selected by screening, or living in areas where all children are infected) may increase weight gain over the next one to six months (627 participants, five trials, low quality evidence). The effect size varied across trials from an additional 0.2 kg gain to 1.3 kg. There is currently insufficient evidence to know whether treatment has additional effects on haemoglobin (247 participants, two trials, very low quality evidence); school attendance (0 trials); cognitive functioning (103 participants, two trials, very low quality evidence), or physical well-being (280 participants, three trials, very low quality evidence). Community deworming programmesTreating all children living in endemic areas with a dose of deworming drugs probably has little or no effect on average weight gain (MD 0.04 kg less, 95{\%} CI 0.11 kg less to 0.04 kg more; trials 2719 participants, seven trials, moderate quality evidence), even in settings with high prevalence of infection (290 participants, two trials). A single dose also probably has no effect on average haemoglobin (MD 0.06 g/dL, 95{\%} CI -0.05 lower to 0.17 higher; 1005 participants, three trials, moderate quality evidence), or average cognition (1361 participants, two trials, low quality evidence).Similiarly, regularly treating all children in endemic areas with deworming drugs, given every three to six months, may have little or no effect on average weight gain (MD 0.08 kg, 95{\%} CI 0.11 kg less to 0.27 kg more; 38,392 participants, 10 trials, low quality evidence). The effects were variable across trials; one trial from a low prevalence setting carried out in 1995 found an increase in weight, but nine trials carried out since then found no effect, including five from moderate and high prevalence areas.There is also reasonable evidence that regular treatment probably has no effect on average height (MD 0.02 cm higher, 95{\%} CI 0.14 lower to 0.17 cm higher; 7057 participants, seven trials, moderate quality evidence); average haemoglobin (MD 0.02 g/dL lower; 95{\%} CI 0.08 g/dL lower to 0.04 g/dL higher; 3595 participants, seven trials, low quality evidence); formal tests of cognition (32,486 participants, five trials, moderate quality evidence); exam performance (32,659 participants, two trials, moderate quality evidence); or mortality (1,005,135 participants, three trials, low quality evidence). There is very limited evidence assessing an effect on school attendance and the findings are inconsistent, and at risk of bias (mean attendance 2{\%} higher, 95{\%} CI 4{\%} lower to 8{\%} higher; 20,243 participants, two trials, very low quality evidence).In a sensitivity analysis that only included trials with adequate allocation concealment, there was no evidence of any effect for the main outcomes. AUTHORS' CONCLUSIONS Treating children known to have worm infection may have some nutritional benefits for the individual. However, in mass treatment of all children in endemic areas, there is now substantial evidence that this does not improve average nutritional status, haemoglobin, cognition, school performance, or survival.},
author = {Taylor-Robinson, David C. and Maayan, Nicola and Soares-Weiser, Karla and Donegan, Sarah and Garner, Paul},
doi = {10.1002/14651858.CD000371.pub6},
file = {:Users/hollinal/Documents/mendeley{\_}desktop/Taylor-Robinson et al.{\_}2015.pdf:pdf},
isbn = {1469-493X},
issn = {14651858},
journal = {Cochrane Database of Systematic Reviews},
month = {jul},
number = {7},
pmid = {26202783},
title = {{Deworming drugs for soil-transmitted intestinal worms in children: effects on nutritional indicators, haemoglobin, and school performance}},
url = {http://doi.wiley.com/10.1002/14651858.CD000371.pub6},
volume = {2015},
year = {2015}
}
@techreport{Zhang2013,
abstract = {Null Hypothesis Significance Testing has been widely used in the experimental economics literature. Typically, attention is restricted to type-I-errors. We demonstrate that not taking type-II errors into account is problematic. We also provide evidence, for one prominent area in experimental economics (dictator game experiments), that most studies are severely underpowered, suggesting that their findings are questionable. We then illustrate with several examples how poor (no) power planning can lead to questionable results.},
author = {Zhang, Le and Ortmann, Andreas},
booktitle = {Australian School of Business Working Paper. No. 2013 ECON 32.},
doi = {10.2139/ssrn.2356018},
file = {:Users/hollinal/Documents/mendeley{\_}desktop/Zhang, Ortmann{\_}2013.pdf:pdf},
keywords = {A10,B23,C12,Null Hypothesis Significance Testing,Significance level,Statistical power,Type-I-errors,Type-II errors},
title = {{Exploring the Meaning of Significance in Experimental Economics}},
year = {2013}
}
@article{Ziliak2004,
abstract = {Significance testing as used has no theoretical justification. Our article in the Journal of Economic Literature (1996) showed that of the 182 full-length papers published in the 1980s in the American Economic and Review 70{\%} did not distinguish economic from statistical significance. Since 1996 many colleagues have told us that practice has improved. We interpret their response as an empirical claim, a judgment about a fact. Our colleagues, unhappily, are mistaken: significance testing is getting worse. We find here that in the next decade, the 1990s, of the 137 papers using a test of statistical significance in the AER fully 82{\%} mistook a merely statistically significant finding for an economically significant finding. A super majority (81{\%}) believed that looking at the sign of a coefficient sufficed for science, ignoring size. The mistake is causing economic damage: losses of jobs and justice, and indeed of human lives (especially in, to mention another field enchanted with statistical significance as against substantive significance, medical science). The confusion between fit and importance is causing false hypotheses to be accepted and true hypotheses to be rejected. We propose a publication standard for the future: "Tell me the oomph of your coefficient; and do not confuse it with merely statistical significance." {\textcopyright} 2004 Published by Elsevier Inc.},
author = {Ziliak, Stephen T. and McCloskey, Deirdre N.},
doi = {10.1016/j.socec.2004.09.024},
file = {:Users/hollinal/Documents/mendeley{\_}desktop/Ziliak, McCloskey{\_}2004.pdf:pdf},
isbn = {1053-5357},
issn = {10535357},
journal = {The Journal of Socio-Economics},
keywords = {American Economic Review,Regression,Significance,Standard error,Testing},
month = {nov},
number = {5},
pages = {527--546},
title = {{Size matters: the standard error of regressions in the American Economic Review}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1053535704000836},
volume = {33},
year = {2004}
}
